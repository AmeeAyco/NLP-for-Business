{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7b0ziVVABCR"
   },
   "source": [
    "### Project Gutenberg:  Topic Modelling Using Unsupervised NLP\n",
    "\n",
    "https://www.gutenberg.org/\n",
    "\n",
    "Assignment 2: Devika Pace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSvl4Do7__sq"
   },
   "source": [
    "[Import Libaries](#0)\n",
    "\n",
    "  [Select and load book(s) from Project Gutenberg](#1)\n",
    "  - Alice In Wonderland\n",
    "  - Grimm's Fairy Tales\n",
    "  - Walden \n",
    "\n",
    "[Pre-process Text](#2)\n",
    "- Clean\n",
    "- Tokenize\n",
    "- Stop Word Removal\n",
    "- Stemming and Lemmatization\n",
    "\n",
    "[Vectorization](#3)\n",
    "- Count Vectorizer\n",
    "- Tf-idf Vectorizer\n",
    "- Sparsity\n",
    "\n",
    "[Topic Model with Unsupervised Clustering Algorithm](#4)\n",
    "- LDA\n",
    "- NNMF\n",
    "- LSI\n",
    "\n",
    "[Metrics & Results](#5)\n",
    "- Tuning\n",
    "- Visualization\n",
    "- Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKDO2hJX4T0O"
   },
   "source": [
    "<a name=\"0\"></a>\n",
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dHwRRqcFpRFc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "               \n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTGkSUly34wV"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "### **Project Gutenberg**\n",
    "\n",
    "We will download a few different texts for comparison's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p1LHtrItrKuD"
   },
   "outputs": [],
   "source": [
    "url_alice = \"https://gutenberg.org/files/11/11-0.txt\"      # Alice in Wonderland\n",
    "url_grimm = \"https://gutenberg.org/files/2591/2591-0.txt\"  # Grimm's Fairy Tales\n",
    "url_walden = \"https://gutenberg.org/files/205/205-0.txt\"   # Walden\n",
    "\n",
    "def get_gutenberg_text(url):\n",
    "\n",
    "  with urlopen(url) as response:\n",
    "    html_content = response.read()\n",
    "  encoding = response.headers.get_content_charset('utf-8')\n",
    "  text = html_content.decode(encoding)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqjmdLJB3BtZ"
   },
   "source": [
    "**Alice in Wonderland**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQELxVeg0zZD",
    "outputId": "91705f17-38df-4d73-b106-181022e10ca3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "text = get_gutenberg_text(url_alice)\n",
    "print(f'length of text response: {len(text)}, length of split: {len(text.split(\"***\"))}\\n')\n",
    "text.split('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28lFD6hG074c",
    "outputId": "0a803985-ef8b-4169-d8e7-d5900d5b7576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF ALIC TEXT: 147994\n",
      "\n",
      "************************START OF ALICE TEXT*****************************:\r\n",
      "\r\n",
      "[Illustration]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Alice’s Adventures in Wonderland\r\n",
      "\r\n",
      "by Lewis Carroll\r\n",
      "\r\n",
      "THE MILLENNIUM FULCRUM EDITION 3.0\r\n",
      "\r\n",
      "Contents\r\n",
      "\r\n",
      " CHAPTER I.     Down the Rabbit-Hole\r\n",
      " CHAPTER II.    The Pool of Tears\r\n",
      " CHAPTER III.   A Caucus-Race and a Long Tale\r\n",
      " CHAPTER IV.    The Rabbit Sends in a Little Bill\r\n",
      " CHAPTER V.     Advice from a Caterpillar\r\n",
      " CHAPTER VI.    Pig and Pepper\r\n",
      " CHAPTER VII.   A Mad Tea-Party\r\n",
      " CHAPTER VIII.  The Queen’s Croquet-Ground\r\n",
      " CHAPTER IX.    The Mock Turtle’s Story\r\n",
      " CHAPTER X.     The Lobster Quadrille\r\n",
      " CHAPTER XI.    Who Stole the Tarts?\r\n",
      " CHAPTER XII.   Alice’s Evidence\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "CHAPTER I.\r\n",
      "Down the Rabbit-Hole\r\n",
      "\r\n",
      "\r\n",
      "Alice was beginning to get very tired of sitting by her sister on the\r\n",
      "bank, and of having nothing to do: once or twice she had peeped into\r\n",
      "the book her sister was reading, but it had no pictures or\r\n",
      "conversations in it, “and what is the use of a book,” thought Alice\r\n",
      "“without pictures or conversations?”\r\n",
      "\r\n",
      "So she was considering in her own mind (as well as she could, for the\r\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure of\r\n",
      "making a daisy-chain would be worth the trouble of getting up and\r\n",
      "picking the daisies, when suddenly a White Rabbit with pink eyes ran\r\n",
      "close by her.\r\n",
      "\r\n",
      "There was nothing so _very_ remarkable in that; nor did Alice think it\r\n",
      "so _very_ much out of the way to hear the Rabbit say to itself, “Oh\r\n",
      "dear! Oh dear! I shall be late!” (when she thought it over afterwards,\r\n",
      "it occurred to her that she ought to have wondered at this, but at the\r\n",
      "time it all seemed quite natural); but when the Rabbit actually _took a\r\n",
      "watch out of its waistcoat-pocket_, and looked at it, and then hurried\r\n",
      "on, Alice started to her feet, for it flashed across her mind that she\r\n",
      "had never before seen a rabbit with either a waistcoat-pocket, or a\r\n",
      "watch to take out of it, and burning with curiosity, she ran across the\r\n",
      "field after it, and fortunately was just in time to see it pop down a\r\n",
      "large rabbit-hole under the hedge.\r\n",
      "\r\n",
      "In another moment down went Alice after it, never once considering how\r\n",
      "in the world she was to get out again.\r\n",
      "\r\n",
      "The rabbit-hole went straight on like a tunnel for some way, and then\r\n",
      "dipped suddenly down, so suddenly that Alice had not a moment to think\r\n",
      "about stopping herself before she found herself falling down a very\r\n",
      "deep well.\r\n",
      "\r\n",
      "Either the well was very deep, or she fell very slowly, for she had\r\n",
      "plenty of time as she went down to look about her and to wonder what\r\n",
      "was going to happen next. First, she tried to look down and make out\r\n",
      "what she was coming to, but it was too dark to see anything; then she\r\n",
      "looked at the sides of the well, and noticed that they were filled with\r\n",
      "cupboards and book-shelves; here and there she saw maps and pictures\r\n",
      "hung upon pegs. She took down a jar from one of the shelves as she\r\n",
      "passed; it was labelled “ORANGE MARMALADE”, but to her great\r\n",
      "disappointment it was empty: she did not like to drop the jar for fear\r\n",
      "of killing somebody \n",
      "\n",
      "**************************END OF ALICE TEXT*****************************:\n",
      "\n",
      "to the waving of the reeds—the rattling\r\n",
      "teacups would change to tinkling sheep-bells, and the Queen’s shrill\r\n",
      "cries to the voice of the shepherd boy—and the sneeze of the baby, the\r\n",
      "shriek of the Gryphon, and all the other queer noises, would change\r\n",
      "(she knew) to the confused clamour of the busy farm-yard—while the\r\n",
      "lowing of the cattle in the distance would take the place of the Mock\r\n",
      "Turtle’s heavy sobs.\r\n",
      "\r\n",
      "Lastly, she pictured to herself how this same little sister of hers\r\n",
      "would, in the after-time, be herself a grown woman; and how she would\r\n",
      "keep, through all her riper years, the simple and loving heart of her\r\n",
      "childhood: and how she would gather about her other little children,\r\n",
      "and make _their_ eyes bright and eager with many a strange tale,\r\n",
      "perhaps even with the dream of Wonderland of long ago: and how she\r\n",
      "would feel with all their simple sorrows, and find a pleasure in all\r\n",
      "their simple joys, remembering her own child-life, and the happy summer\r\n",
      "days.\r\n",
      "\r\n",
      "THE END \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alice = text.split('***')[2]\n",
    "print(f'LENGTH OF ALIC TEXT: {len(alice)}')\n",
    "print(f'\\n************************START OF ALICE TEXT*****************************:{alice[0:3000]}')\n",
    "print(f'\\n**************************END OF ALICE TEXT*****************************:\\n\\n{alice[-1000:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybLpHxXn3Ocv"
   },
   "source": [
    "**Grimm's Fairy Tales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dxlvo6_ysVR0",
    "outputId": "fc25dcf6-f96d-461b-9b6f-6d083636894e"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "text = get_gutenberg_text(url_grimm)\n",
    "print(f'length of text response: {len(text)}, length of split: {len(text.split(\"***\"))}\\n')\n",
    "text.split('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnkZuAW1sia3",
    "outputId": "563b5461-a69a-4cfd-d178-d4bba1fded57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF GRIMM TEXT: 528873\n",
      "\n",
      "************************START OF GRIMM TEXT*****************************:\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Grimms’ Fairy Tales\r\n",
      "\r\n",
      "By Jacob Grimm and Wilhelm Grimm\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "PREPARER’S NOTE\r\n",
      "\r\n",
      "     The text is based on translations from\r\n",
      "     the Grimms’ Kinder und Hausmärchen by\r\n",
      "     Edgar Taylor and Marian Edwardes.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "CONTENTS:\r\n",
      "\r\n",
      "     THE GOLDEN BIRD\r\n",
      "     HANS IN LUCK\r\n",
      "     JORINDA AND JORINDEL\r\n",
      "     THE TRAVELLING MUSICIANS\r\n",
      "     OLD SULTAN\r\n",
      "     THE STRAW, THE COAL, AND THE BEAN\r\n",
      "     BRIAR ROSE\r\n",
      "     THE DOG AND THE SPARROW\r\n",
      "     THE TWELVE DANCING PRINCESSES\r\n",
      "     THE FISHERMAN AND HIS WIFE\r\n",
      "     THE WILLOW-WREN AND THE BEAR\r\n",
      "     THE FROG-PRINCE\r\n",
      "     CAT AND MOUSE IN PARTNERSHIP\r\n",
      "     THE GOOSE-GIRL\r\n",
      "     THE ADVENTURES OF CHANTICLEER AND PARTLET\r\n",
      "       1. HOW THEY WENT TO THE MOUNTAINS TO EAT NUTS\r\n",
      "       2. HOW CHANTICLEER AND PARTLET WENT TO VISIT MR KORBES\r\n",
      "     RAPUNZEL\r\n",
      "     FUNDEVOGEL\r\n",
      "     THE VALIANT LITTLE TAILOR\r\n",
      "     HANSEL AND GRETEL\r\n",
      "     THE MOUSE, THE BIRD, AND THE SAUSAGE\r\n",
      "     MOTHER HOLLE\r\n",
      "     LITTLE RED-CAP [LITTLE RED RIDING HOOD]\r\n",
      "     THE ROBBER BRIDEGROOM\r\n",
      "     TOM THUMB\r\n",
      "     RUMPELSTILTSKIN\r\n",
      "     CLEVER GRETEL\r\n",
      "     THE OLD MAN AND HIS GRANDSON\r\n",
      "     THE LITTLE PEASANT\r\n",
      "     FREDERICK AND CATHERINE\r\n",
      "     SWEETHEART ROLAND\r\n",
      "     SNOWDROP\r\n",
      "     THE PINK\r\n",
      "     CLEVER ELSIE\r\n",
      "     THE MISER IN THE BUSH\r\n",
      "     ASHPUTTEL\r\n",
      "     THE WHITE SNAKE\r\n",
      "     THE WOLF AND THE SEVEN LITTLE KIDS\r\n",
      "     THE QUEEN BEE\r\n",
      "     THE ELVES AND THE SHOEMAKER\r\n",
      "     THE JUNIPER-TREE\r\n",
      "     the juniper-tree.\r\n",
      "     THE TURNIP\r\n",
      "     CLEVER HANS\r\n",
      "     THE THREE LANGUAGES\r\n",
      "     THE FOX AND THE CAT\r\n",
      "     THE FOUR CLEVER BROTHERS\r\n",
      "     LILY AND THE LION\r\n",
      "     THE FOX AND THE HORSE\r\n",
      "     THE BLUE LIGHT\r\n",
      "     THE RAVEN\r\n",
      "     THE GOLDEN GOOSE\r\n",
      "     THE WATER OF LIFE\r\n",
      "     THE TWELVE HUNTSMEN\r\n",
      "     THE KING OF THE GOLDEN MOUNTAIN\r\n",
      "     DOCTOR KNOWALL\r\n",
      "     THE SEVEN RAVENS\r\n",
      "     THE WEDDING OF MRS FOX\r\n",
      "     FIRST STORY\r\n",
      "     SECOND STORY\r\n",
      "     THE SALAD\r\n",
      "     THE STORY OF THE YOUTH WHO WENT FORTH TO LEARN WHAT FEAR WAS\r\n",
      "     KING GRISLY-BEARD\r\n",
      "     IRON HANS\r\n",
      "     CAT-SKIN\r\n",
      "     SNOW-WHITE AND ROSE-RED\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "THE BROTHERS GRIMM FAIRY TALES\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "THE GOLDEN BIRD\r\n",
      "\r\n",
      "\r\n",
      "A certain king had a beautiful garden, and in the garden stood a tree\r\n",
      "which bore golden apples. These apples were always counted, and about\r\n",
      "the time when they began to grow ripe it was found that every night one\r\n",
      "of them was gone. The king became very angry at this, and ordered the\r\n",
      "gardener to keep watch all night under the tree. The gardener set his\r\n",
      "eldest son to watch; but about twelve o’clock he fell asleep, and in\r\n",
      "the morning another of the apples was missing. Then the second son was\r\n",
      "ordered to watch; and at midnight he too fell asleep, and in the morning\r\n",
      "another apple was gone. Then the third son offered to keep watch; but\r\n",
      "the gardener at first would not let him, for fear some harm should come\r\n",
      "to him: however, at last he consented, and the young man laid himself\r\n",
      "under the tree to watch. As the clock struck twelve he heard a rustling\r\n",
      "noise in the air, and a bird \n",
      "\n",
      "*******************END OF GRIMM TEXT (SNOW WHITE)***********************:\n",
      "\n",
      "rds, but gave the wicked creature a single\r\n",
      "blow with his paw, and he did not move again.\r\n",
      "\r\n",
      "The girls had run away, but the bear called to them: ‘Snow-white and\r\n",
      "Rose-red, do not be afraid; wait, I will come with you.’ Then they\r\n",
      "recognized his voice and waited, and when he came up to them suddenly\r\n",
      "his bearskin fell off, and he stood there a handsome man, clothed all in\r\n",
      "gold. ‘I am a king’s son,’ he said, ‘and I was bewitched by that wicked\r\n",
      "dwarf, who had stolen my treasures; I have had to run about the forest\r\n",
      "as a savage bear until I was freed by his death. Now he has got his\r\n",
      "well-deserved punishment.\r\n",
      "\r\n",
      "Snow-white was married to him, and Rose-red to his brother, and they\r\n",
      "divided between them the great treasure which the dwarf had gathered\r\n",
      "together in his cave. The old mother lived peacefully and happily with\r\n",
      "her children for many years. She took the two rose-trees with her, and\r\n",
      "they stood before her window, and every year bore the most beautiful\r\n",
      "roses, white and red.\r\n",
      "\r\n",
      "\r\n",
      "\n",
      "******************************ABOUT*************************************:\n",
      "**\r\n",
      "\r\n",
      "\r\n",
      "The Brothers Grimm, Jacob (1785-1863) and Wilhelm (1786-1859), were born\r\n",
      "in Hanau, near Frankfurt, in the German state of Hesse. Throughout\r\n",
      "their lives they remained close friends, and both studied law at Marburg\r\n",
      "University. Jacob was a pioneer in the study of German philology,\r\n",
      "and although Wilhelm’s work was hampered by poor health the brothers\r\n",
      "collaborated in the creation of a German dictionary, not completed until\r\n",
      "a century after their deaths. But they were best (and universally) known\r\n",
      "for the collection of over two hundred folk tales they made from oral\r\n",
      "sources and published in two volumes of ‘Nursery and Household Tales’ in\r\n",
      "1812 and 1814. Although their intention was to preserve such material as\r\n",
      "part of German cultural and literary history, and their collection was\r\n",
      "first published with scholarly notes and no illustration, the tales soon\r\n",
      "came into the possession of young readers. This was in part due to Edgar\r\n",
      "Taylor, who made the first English translation in 1823, selecting about\r\n",
      "fifty stories ‘with the amusement of some young friends principally in\r\n",
      "view.’ They have been an essential ingredient of children’s reading ever\r\n",
      "since.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grimm = text.split('***')[2]\n",
    "grimm_about = text.split('***')[3]\n",
    "print(f'LENGTH OF GRIMM TEXT: {len(grimm)}')\n",
    "print(f'\\n************************START OF GRIMM TEXT*****************************:{grimm[0:3000]}')\n",
    "print(f'\\n*******************END OF GRIMM TEXT (SNOW WHITE)***********************:\\n\\n{grimm[-1000:]}')\n",
    "print(f'******************************ABOUT*************************************:\\n{grimm_about}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clzLK6dr6ssE"
   },
   "source": [
    "**Walden**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNuRAdEF6txG",
    "outputId": "53dee313-991a-4fd4-a672-f40bf428a397"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "text = get_gutenberg_text(url_walden)\n",
    "print(f'length of text response: {len(text)}, length of split: {len(text.split(\"***\"))}\\n')\n",
    "text.split('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9zAi-lg6467",
    "outputId": "b8f44914-4d81-4f18-ba74-c956258101b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF ALIC TEXT: 147994\n",
      "\n",
      "************************START OF THOREAU TEXT*****************************:\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "WALDEN\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "and\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "ON THE DUTY OF CIVIL DISOBEDIENCE\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "by Henry David Thoreau\r\n",
      "\r\n",
      "\r\n",
      "cover\r\n",
      "\r\n",
      "\r\n",
      "Contents\r\n",
      "\r\n",
      "\r\n",
      " WALDEN\r\n",
      "\r\n",
      " Economy\r\n",
      " Where I Lived, and What I Lived For\r\n",
      " Reading\r\n",
      " Sounds\r\n",
      " Solitude\r\n",
      " Visitors\r\n",
      " The Bean-Field\r\n",
      " The Village\r\n",
      " The Ponds\r\n",
      " Baker Farm\r\n",
      " Higher Laws\r\n",
      " Brute Neighbors\r\n",
      " House-Warming\r\n",
      " Former Inhabitants and Winter Visitors\r\n",
      " Winter Animals\r\n",
      " The Pond in Winter\r\n",
      " Spring\r\n",
      " Conclusion\r\n",
      "\r\n",
      " ON THE DUTY OF CIVIL DISOBEDIENCE\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "WALDEN\r\n",
      "\r\n",
      "Economy\r\n",
      "\r\n",
      "When I wrote the following pages, or rather the bulk of them, I lived\r\n",
      "alone, in the woods, a mile from any neighbor, in a house which I had\r\n",
      "built myself, on the shore of Walden Pond, in Concord, Massachusetts,\r\n",
      "and earned my living by the labor of my hands only. I lived there two\r\n",
      "years and two months. At present I am a sojourner in civilized life\r\n",
      "again.\r\n",
      "\r\n",
      "I should not obtrude my affairs so much on the notice of my readers if\r\n",
      "very particular inquiries had not been made by my townsmen concerning\r\n",
      "my mode of life, which some would call impertinent, though they do not\r\n",
      "appear to me at all impertinent, but, considering the circumstances,\r\n",
      "very natural and pertinent. Some have asked what I got to eat; if I did\r\n",
      "not feel lonesome; if I was not afraid; and the like. Others have been\r\n",
      "curious to learn what portion of my income I devoted to charitable\r\n",
      "purposes; and some, who have large families, how many poor children I\r\n",
      "maintained. I will therefore ask those of my readers who feel no\r\n",
      "particular interest in me to pardon me if I undertake to answer some of\r\n",
      "these questions in this book. In most books, the _I_, or first person,\r\n",
      "is omitted; in this it will be retained; that, in respect to egotism,\r\n",
      "is the main difference. We commonly do not remember that it is, after\r\n",
      "all, always the first person that is speaking. I should not talk so\r\n",
      "much about myself if there were anybody else whom I knew as well.\r\n",
      "Unfortunately, I am confined to this theme by the narrowness of my\r\n",
      "experience. Moreover, I, on my side, require of every writer, first or\r\n",
      "last, a simple and sincere account of his own life, and not merely what\r\n",
      "he has heard of other men’s lives; some such account as he would send\r\n",
      "to his kindred from a distant land; for if he has lived sincerely, it\r\n",
      "must have been in a distant land to me. Perhaps these pages are more\r\n",
      "particularly addressed to poor students. As for the rest of my readers,\r\n",
      "they will accept such portions as apply to them. I trust that none will\r\n",
      "stretch\n",
      "\n",
      "**************************END OF THOREAU TEXT*****************************:\n",
      "\n",
      "s of the empire. Is\r\n",
      "a democracy, such as we know it, the last improvement possible in\r\n",
      "government? Is it not possible to take a step further towards\r\n",
      "recognizing and organizing the rights of man? There will never be a\r\n",
      "really free and enlightened State, until the State comes to recognize\r\n",
      "the individual as a higher and independent power, from which all its\r\n",
      "own power and authority are derived, and treats him accordingly. I\r\n",
      "please myself with imagining a State at last which can afford to be\r\n",
      "just to all men, and to treat the individual with respect as a\r\n",
      "neighbor; which even would not think it inconsistent with its own\r\n",
      "repose, if a few were to live aloof from it, not meddling with it, nor\r\n",
      "embraced by it, who fulfilled all the duties of neighbors and\r\n",
      "fellow-men. A State which bore this kind of fruit, and suffered it to\r\n",
      "drop off as fast as it ripened, would prepare the way for a still more\r\n",
      "perfect and glorious State, which also I have imagined, but not yet\r\n",
      "anywhere seen.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walden = text.split('***')[2]\n",
    "print(f'LENGTH OF ALIC TEXT: {len(alice)}')\n",
    "print(f'\\n************************START OF THOREAU TEXT*****************************:{walden[0:2500]}')\n",
    "print(f'\\n**************************END OF THOREAU TEXT*****************************:\\n\\n{walden[-1000:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bksk8vSd8qGU"
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "### **Pre-process Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcNVuD8A8z0s",
    "outputId": "f8be671f-fc7a-47a6-ec93-4f758286df67",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop words:\n",
      " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "  n = 25\n",
    "  # clean text (to lowercase, remove punctuation)\n",
    "  text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "\n",
    "  # tokenize text\n",
    "  words = word_tokenize(text)\n",
    "  print('tokenized:\\n', words[:n])\n",
    "\n",
    "  # remove stopwords\n",
    "  words = [w for w in words if w not in stopwords.words('english')]\n",
    "  #print('stop words:\\n', stopwords.words('english'), '\\n')\n",
    "  print('no stop words:\\n', words[:n])\n",
    "\n",
    "  # Lemmatize verbs by specifying pos\n",
    "  lemmed = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "  print('lemmed with pos:\\n', lemmed[:n])\n",
    "\n",
    "  # stemming - remove prefix, suff\n",
    "  stemmed = [PorterStemmer().stem(w) for w in lemmed]\n",
    "  print('stemmed:\\n', stemmed[:n])\n",
    "\n",
    "  return stemmed\n",
    "\n",
    "print('stop words:\\n', stopwords.words('english'), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vr2Qul3hIL87",
    "outputId": "fc085001-6ff1-44e6-f230-4f7f22596ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized:\n",
      " ['illustration', 'alice', 's', 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', 'the', 'millennium', 'fulcrum', 'edition', '3', '0', 'contents', 'chapter', 'i', 'down', 'the', 'rabbit', 'hole', 'chapter', 'ii', 'the']\n",
      "no stop words:\n",
      " ['illustration', 'alice', 'adventures', 'wonderland', 'lewis', 'carroll', 'millennium', 'fulcrum', 'edition', '3', '0', 'contents', 'chapter', 'rabbit', 'hole', 'chapter', 'ii', 'pool', 'tears', 'chapter', 'iii', 'caucus', 'race', 'long', 'tale']\n",
      "lemmed with pos:\n",
      " ['illustration', 'alice', 'adventure', 'wonderland', 'lewis', 'carroll', 'millennium', 'fulcrum', 'edition', '3', '0', 'content', 'chapter', 'rabbit', 'hole', 'chapter', 'ii', 'pool', 'tear', 'chapter', 'iii', 'caucus', 'race', 'long', 'tale']\n",
      "stemmed:\n",
      " ['illustr', 'alic', 'adventur', 'wonderland', 'lewi', 'carrol', 'millennium', 'fulcrum', 'edit', '3', '0', 'content', 'chapter', 'rabbit', 'hole', 'chapter', 'ii', 'pool', 'tear', 'chapter', 'iii', 'caucu', 'race', 'long', 'tale']\n"
     ]
    }
   ],
   "source": [
    "post_alice = preprocess_text(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOzAX0TLI8WX",
    "outputId": "906d6d1d-a117-4548-d8b3-b6d7539c710a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized:\n",
      " ['grimms', 'fairy', 'tales', 'by', 'jacob', 'grimm', 'and', 'wilhelm', 'grimm', 'preparer', 's', 'note', 'the', 'text', 'is', 'based', 'on', 'translations', 'from', 'the', 'grimms', 'kinder', 'und', 'hausm', 'rchen']\n",
      "no stop words:\n",
      " ['grimms', 'fairy', 'tales', 'jacob', 'grimm', 'wilhelm', 'grimm', 'preparer', 'note', 'text', 'based', 'translations', 'grimms', 'kinder', 'und', 'hausm', 'rchen', 'edgar', 'taylor', 'marian', 'edwardes', 'contents', 'golden', 'bird', 'hans']\n",
      "lemmed with pos:\n",
      " ['grimms', 'fairy', 'tales', 'jacob', 'grimm', 'wilhelm', 'grimm', 'preparer', 'note', 'text', 'base', 'translations', 'grimms', 'kinder', 'und', 'hausm', 'rchen', 'edgar', 'taylor', 'marian', 'edwardes', 'content', 'golden', 'bird', 'hans']\n",
      "stemmed:\n",
      " ['grimm', 'fairi', 'tale', 'jacob', 'grimm', 'wilhelm', 'grimm', 'prepar', 'note', 'text', 'base', 'translat', 'grimm', 'kinder', 'und', 'hausm', 'rchen', 'edgar', 'taylor', 'marian', 'edward', 'content', 'golden', 'bird', 'han']\n"
     ]
    }
   ],
   "source": [
    "post_grimm = preprocess_text(grimm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQh053deJE9k",
    "outputId": "feaebb35-c6b2-416a-c7ff-a0cf528e478d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized:\n",
      " ['walden', 'and', 'on', 'the', 'duty', 'of', 'civil', 'disobedience', 'by', 'henry', 'david', 'thoreau', 'cover', 'contents', 'walden', 'economy', 'where', 'i', 'lived', 'and', 'what', 'i', 'lived', 'for', 'reading']\n",
      "no stop words:\n",
      " ['walden', 'duty', 'civil', 'disobedience', 'henry', 'david', 'thoreau', 'cover', 'contents', 'walden', 'economy', 'lived', 'lived', 'reading', 'sounds', 'solitude', 'visitors', 'bean', 'field', 'village', 'ponds', 'baker', 'farm', 'higher', 'laws']\n",
      "lemmed with pos:\n",
      " ['walden', 'duty', 'civil', 'disobedience', 'henry', 'david', 'thoreau', 'cover', 'content', 'walden', 'economy', 'live', 'live', 'read', 'sound', 'solitude', 'visitors', 'bean', 'field', 'village', 'ponds', 'baker', 'farm', 'higher', 'laws']\n",
      "stemmed:\n",
      " ['walden', 'duti', 'civil', 'disobedi', 'henri', 'david', 'thoreau', 'cover', 'content', 'walden', 'economi', 'live', 'live', 'read', 'sound', 'solitud', 'visitor', 'bean', 'field', 'villag', 'pond', 'baker', 'farm', 'higher', 'law']\n"
     ]
    }
   ],
   "source": [
    "post_walden = preprocess_text(walden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZnjUCzlJSUJ"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "### **Vectorize Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgwnkWv2LTRn",
    "outputId": "1728c7a0-49ff-4567-9e51-859226e4dd23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12306, 44860, 54684)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_alice), len(post_grimm), len(post_walden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SbpXd5UJaYd",
    "outputId": "59be4689-db43-4557-ecab-e23a5a7c05b1"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', min_df=10,\n",
    "                             stop_words='english', lowercase=True, \n",
    "                             token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', min_df=10,  \n",
    "                             stop_words='english', lowercase=True, \n",
    "                             token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "\n",
    "vec_alice = vectorizer.fit_transform(post_alice)\n",
    "vec_tfidf_alice = tfidf_vectorizer.fit_transform(post_alice)\n",
    "\n",
    "vec_grimm = vectorizer.fit_transform(post_grimm)\n",
    "vec_tfidf_grimm = tfidf_vectorizer.fit_transform(post_grimm)\n",
    "\n",
    "vec_walden = vectorizer.fit_transform(post_walden)\n",
    "vec_tfidf_walden = tfidf_vectorizer.fit_transform(post_walden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = {'vec_alice': vec_alice, 'vec_tfidf_alice':vec_tfidf_alice, 'vec_grimm':vec_grimm, \n",
    "        'vec_tfidf_grimm': vec_tfidf_grimm, 'vec_walden': vec_walden, 'vec_tfidf_walden':vec_tfidf_walden}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sparsity(key,vec):\n",
    "    #materialize the sparse data\n",
    "    data_dense = vec.todense()\n",
    "    # compute sparsity as % of non-zero cells\n",
    "    print(key, \"sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_alice sparsicity:  0.22439548093464512 %\n",
      "vec_tfidf_alice sparsicity:  0.22439548093464512 %\n",
      "vec_grimm sparsicity:  0.0934931314461793 %\n",
      "vec_tfidf_grimm sparsicity:  0.0934931314461793 %\n",
      "vec_walden sparsicity:  0.05316807626200962 %\n",
      "vec_tfidf_walden sparsicity:  0.05316807626200962 %\n"
     ]
    }
   ],
   "source": [
    "for k,v in vecs.items():\n",
    "    check_sparsity(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Choose least sparse ('Alice in Wonderland') vs most sparse ('Walden') to compare results.  We will start with Alice as it is ~20-25% size. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose 'Alice in Wonderland' as it is the least sparse and also ~20-25% the size of most sparse ('Walden')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized = vec_tfidf_alice.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "### Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bO8yQ9C8LnhT",
    "outputId": "53c3bb95-5b3b-49b5-85a1-26887ff27ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12306, 10)\n",
      "(12306, 10)\n",
      "(12306, 10)\n"
     ]
    }
   ],
   "source": [
    "# Non-Negative Matrix Factorization Model\n",
    "nmf_model = NMF(n_components=10)\n",
    "nmf_Z = nmf_model.fit_transform(data_vectorized)\n",
    "print(nmf_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    " \n",
    "# Latent Semantic Indexing Model\n",
    "lsi_model = TruncatedSVD(n_components=10)\n",
    "lsi_Z = lsi_model.fit_transform(data_vectorized)\n",
    "print(lsi_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    "\n",
    "# Latent Dirichlet Allocation Model\n",
    "lda_model = LatentDirichletAllocation(n_components=10, max_iter=10, learning_method='online') # no of components = no. of topics\n",
    "lda_Z = lda_model.fit_transform(data_vectorized)\n",
    "print(lda_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EvoJ_BtEL541"
   },
   "outputs": [],
   "source": [
    "# inspect the inferred topics\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Uyq725eVSzLt"
   },
   "outputs": [],
   "source": [
    "# check log-likelihood and perplexity of LDA model\n",
    "def print_performance(model, data_vectorized):   \n",
    "    # log likelihood: Higher the better\n",
    "    print(\"Log Likelihood: \", model.score(data_vectorized))\n",
    "    # perplexity: lower the better, perplexity = exp(-1. * log-likelihood per word)\n",
    "    print(\"Perplexity: \", model.perplexity(data_vectorized))\n",
    "    # model parameters\n",
    "    pprint(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncYzKbq5MCuG",
    "outputId": "b24339e9-43fc-4d90-ecb5-3ee3ff5dde6d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Model:\n",
      "Topic 0:\n",
      "[('commenc', 4.802616494093945), ('deliber', 0.0), ('bear', 0.0), ('berri', 0.0), ('beneath', 0.0), ('bend', 0.0), ('belong', 0.0), ('bell', 0.0), ('believ', 0.0), ('behold', 0.0)]\n",
      "Topic 1:\n",
      "[('accord', 4.469338245807232), ('deliber', 0.0), ('beast', 0.0), ('besid', 0.0), ('berri', 0.0), ('beneath', 0.0), ('bend', 0.0), ('belong', 0.0), ('bell', 0.0), ('believ', 0.0)]\n",
      "Topic 2:\n",
      "[('cow', 3.427436461889216), ('creatur', 2.5369695766521796e-09), ('board', 5.0595930924965667e-11), ('bright', 3.975885020692307e-11), ('danger', 3.5361889918675497e-13), ('deal', 1.3369537711553856e-13), ('aliv', 1.1726196188636384e-14), ('cellar', 2.4116117172824423e-15), ('cove', 1.556486667553093e-15), ('curiou', 4.3775063338948756e-16)]\n",
      "Topic 3:\n",
      "[('burst', 3.370134935794663), ('board', 1.67095489468018e-11), ('cultiv', 6.260030873759212e-14), ('curiou', 6.485346577221619e-15), ('art', 2.9463980384235572e-15), ('bank', 5.0291651221996e-16), ('daili', 9.349944481859502e-17), ('birch', 7.41508337681765e-17), ('case', 7.144178990260159e-17), ('concord', 2.905437579704796e-17)]\n",
      "Topic 4:\n",
      "[('bring', 3.21614802406645), ('bright', 3.096088161496924e-08), ('clean', 4.673936015469034e-09), ('aliv', 4.2339459003687736e-10), ('danger', 1.2956941691220862e-10), ('cellar', 1.1458958990391782e-11), ('curiou', 3.890696468916598e-12), ('attend', 1.953032449385278e-12), ('color', 1.9423290381299983e-12), ('art', 1.1002168668262444e-12)]\n",
      "Topic 5:\n",
      "[('cake', 3.2085059003484115), ('care', 8.17224203202858e-06), ('civil', 6.851441853104355e-06), ('caus', 4.3192630194495444e-08), ('blue', 2.5405235664884293e-08), ('custom', 1.304585835052288e-08), ('clean', 8.269519934983493e-09), ('clear', 4.95871860919647e-10), ('boat', 2.221664688189722e-10), ('attend', 1.979506058450235e-12)]\n",
      "Topic 6:\n",
      "[('burn', 3.6255957411217126), ('betray', 3.419167355832735e-08), ('blue', 2.82112546485205e-08), ('cultiv', 5.223112073895637e-10), ('cellar', 2.509742190527566e-10), ('curiou', 6.961327540883615e-11), ('color', 4.198666618389178e-11), ('attend', 2.331336491251343e-11), ('art', 6.74307202435802e-12), ('bank', 5.299393188776844e-13)]\n",
      "Topic 7:\n",
      "[('amus', 2.8717854657634607), ('creatur', 0.00013002740710039512), ('bright', 2.7198041642037056e-06), ('board', 1.504250222547951e-06), ('custom', 4.102570209614048e-07), ('deal', 1.4679273663089013e-07), ('clear', 3.692832603996467e-08), ('danger', 2.3165274230631835e-08), ('boat', 6.530856485554913e-09), ('cri', 1.4969779014563563e-10)]\n",
      "Topic 8:\n",
      "[('advantag', 3.129694188782414), ('creatur', 9.487902621892719e-05), ('bright', 2.9556256949742064e-06), ('board', 9.79631431652161e-07), ('clean', 6.539300261589436e-08), ('danger', 1.4258354435663351e-08), ('aliv', 4.64646220356185e-10), ('cove', 4.833619997715508e-11), ('bank', 1.2124754256577866e-12), ('birch', 8.83768032323611e-13)]\n",
      "Topic 9:\n",
      "[('cover', 2.962653518443011), ('board', 0.00013080946750474272), ('blue', 9.298085640245578e-05), ('custom', 8.818112435755328e-05), ('deal', 6.950935255095174e-05), ('betray', 1.3646894607754012e-05), ('aliv', 4.2968183841328454e-07), ('cellar', 9.289017447412933e-08), ('cultiv', 4.784886001756652e-08), ('curiou', 2.6202401525516258e-08)]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print(\"NMF Model:\")\n",
    "print_topics(nmf_model, tfidf_vectorizer)\n",
    "print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lPVH-oQMC02",
    "outputId": "77ac077f-745d-4726-f8df-a5a5f5841e88",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI Model:\n",
      "Topic 0:\n",
      "[('commenc', 0.9999999999992503), ('blue', 7.639232457802469e-07), ('clear', 5.792938882762372e-07), ('caus', 3.4419012160079515e-07), ('custom', 2.7342775705116873e-07), ('clean', 2.4346426879318273e-07), ('betray', 1.8371094883747335e-07), ('boat', 1.83515437870189e-07), ('care', 1.4457178105967557e-07), ('berri', 1.2656829191697055e-07)]\n",
      "Topic 1:\n",
      "[('accord', 0.9999999999972833), ('boat', 1.1277693223294767e-06), ('betray', 9.321143042735877e-07), ('danger', 4.3474945120659707e-07), ('attend', 4.059616045551533e-07), ('cultiv', 3.9233964047406565e-07), ('curiou', 3.3378374790121177e-07), ('death', 2.844353499242574e-07), ('art', 2.6799717683316124e-07), ('daili', 2.454350546957412e-07)]\n",
      "Topic 2:\n",
      "[('cow', 0.9999861750948789), ('clear', 0.002292425513548705), ('boat', 0.001423991912573567), ('cultiv', 0.0011439583362818572), ('bright', 0.001119127248411035), ('board', 0.001093868042865346), ('danger', 0.0009729259624226912), ('art', 0.0009723898879935113), ('betray', 0.0006826544135054681), ('cover', 0.0004840328415862405)]\n",
      "Topic 3:\n",
      "[('burst', 0.9999939788445118), ('blue', 0.001285536163096775), ('deal', 0.0012448729411681436), ('cri', 0.0009280221256304779), ('clean', 0.000675148674795103), ('caus', 0.0006738651578931856), ('curiou', 0.0004774831272866471), ('care', 0.0004342931737973555), ('custom', 0.00026601384215165554), ('death', 0.0002532329737523585)]\n",
      "Topic 4:\n",
      "[('bring', 0.9998584639416834), ('cri', 0.005228677830308142), ('cellar', 0.0037332208318752256), ('caus', 0.0028265949776373218), ('deal', 0.0021969429174374736), ('cake', 0.002088266127509786), ('advantag', 0.0020463663307276336), ('creatur', 0.001883709275343101), ('color', 0.0012666371682373521), ('amus', 0.0011747617682726077)]\n",
      "Topic 5:\n",
      "[('cake', 0.9997511860680393), ('blue', 0.008781193980162805), ('custom', 0.00784353402831879), ('deal', 0.007681823646240973), ('clean', 0.0033796260787718685), ('caus', 0.003236092129368112), ('aliv', 0.002800071129967042), ('cultiv', 0.0019884272579071445), ('attend', 0.0018952037985729376), ('cellar', 0.0017876846260779459)]\n",
      "Topic 6:\n",
      "[('burn', 0.8890441610250159), ('deal', 0.006982804761967866), ('aliv', 0.0048511363379623515), ('cri', 0.004037112253311477), ('cake', 0.0018574111037811883), ('danger', 0.0013869207645796945), ('construct', 0.0010616979216371385), ('certainli', 0.0010129171183826456), ('bring', 0.0008010071737202238), ('blue', 0.0007810222666935866)]\n",
      "Topic 7:\n",
      "[('amus', 0.8810299029526474), ('burn', 0.45291716886700495), ('caus', 0.02931244078304009), ('blue', 0.02679910673450634), ('deal', 0.012078216809568061), ('custom', 0.01124643975600896), ('care', 0.010174316013950819), ('attend', 0.0068929672365265), ('cultiv', 0.00635209626554286), ('cake', 0.00583520820771339)]\n",
      "Topic 8:\n",
      "[('advantag', 0.9918002395170582), ('amus', 0.1065496568603641), ('burn', 0.05847220799688277), ('blue', 0.022505995779360365), ('caus', 0.01783383958234674), ('clear', 0.011004336296188624), ('attend', 0.00766097970948299), ('aliv', 0.0063617253357172165), ('care', 0.005233404596359736), ('deal', 0.0049496545954782235)]\n",
      "Topic 9:\n",
      "[('cover', 0.995443677324743), ('deal', 0.030537880537357565), ('attend', 0.022941937168824634), ('care', 0.022358484850361016), ('creatur', 0.019367470980758077), ('custom', 0.015851447750937237), ('blue', 0.01318470506821095), ('concord', 0.008210740052369214), ('berri', 0.007203959099934935), ('amus', 0.007106852325450691)]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print(\"LSI Model:\")\n",
    "print_topics(lsi_model, tfidf_vectorizer)\n",
    "print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCI-eZENMCiG",
    "outputId": "07b9d8da-12f6-4be2-83b2-a2690c7b206e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic 0:\n",
      "[('commenc', 552.3207036587878), ('accord', 392.87403334028346), ('care', 75.14476849108297), ('concord', 36.09700588024805), ('buri', 20.19692115780026), ('busi', 17.64346548398226), ('close', 13.235523484191035), ('circumst', 10.11434304835165), ('atmospher', 7.978538925864113), ('chang', 0.1000001935675249)]\n",
      "Topic 1:\n",
      "[('cake', 107.20928146020528), ('bring', 106.46982238868219), ('caus', 68.01243973897294), ('buy', 41.60519737224702), ('cultiv', 40.56072114080348), ('bank', 36.91336198224037), ('awak', 30.110261839278827), ('circul', 28.27264823204057), ('behold', 22.79021499248575), ('better', 22.05961407635613)]\n",
      "Topic 2:\n",
      "[('art', 44.34590117700969), ('curiou', 43.4203234541159), ('daili', 32.86179963369215), ('degre', 31.379430038394034), ('best', 30.787374297957964), ('cost', 29.000238416759238), ('alreadi', 25.028142672590384), ('admir', 24.4153768493046), ('dark', 20.21390088676006), ('alway', 19.39467999521582)]\n",
      "Topic 3:\n",
      "[('burn', 90.8294982092057), ('bright', 81.32450217847676), ('creatur', 73.74095999657165), ('clean', 52.50449458822238), ('death', 42.58235447462436), ('berri', 38.683592750280845), ('deepest', 24.76632071366321), ('boy', 22.45887040577019), ('acquaint', 20.276457467217032), ('act', 18.397548719285336)]\n",
      "Topic 4:\n",
      "[('blue', 63.16739347041237), ('danger', 54.72071632412494), ('clear', 51.80011511628534), ('color', 39.27124748035253), ('coffe', 35.37125284300946), ('anoth', 28.087636894140438), ('cloud', 28.02021469189714), ('allow', 24.952763390783467), ('countri', 21.246280964602317), ('deed', 18.681334955666053)]\n",
      "Topic 5:\n",
      "[('custom', 73.99121636027012), ('cri', 43.271586713643394), ('cellar', 33.714316932704556), ('blood', 32.658057336015155), ('brister', 31.299833505121672), ('cattl', 31.029673150926975), ('come', 27.542315042133154), ('arriv', 26.700638734182665), ('apart', 24.481025058366175), ('constitut', 21.112248748757192)]\n",
      "Topic 6:\n",
      "[('burst', 119.40565649502774), ('advantag', 98.8668270311057), ('civil', 87.47082345189071), ('construct', 37.231361685764355), ('collect', 29.968568050229802), ('battl', 25.24997006837809), ('beneath', 24.62555870384022), ('companion', 22.7101352070769), ('actual', 21.12618474571652), ('bush', 17.22398149564916)]\n",
      "Topic 7:\n",
      "[('cow', 128.5100585528642), ('cover', 75.0803401150423), ('attend', 43.300948912277015), ('cove', 41.73404787478479), ('deliber', 25.453786715762774), ('citi', 24.967471281216973), ('answer', 23.703603567610777), ('bar', 20.511979712602553), ('chip', 19.235497924897988), ('advanc', 18.506537316501973)]\n",
      "Topic 8:\n",
      "[('amus', 93.95908554501783), ('betray', 66.67589407347597), ('board', 60.678492982316065), ('deal', 51.11214945150237), ('appl', 42.73579456378011), ('add', 33.37152110383648), ('brick', 28.29767983842576), ('absolut', 27.01873324044753), ('consid', 21.154446685984865), ('america', 19.777046255489715)]\n",
      "Topic 9:\n",
      "[('boat', 47.639466862455244), ('aliv', 45.50940631314936), ('case', 36.958524218422774), ('birch', 36.52542653100866), ('certainli', 34.01716779640706), ('brown', 31.926915254605195), ('cat', 30.836367211561633), ('ceas', 28.67689459748574), ('approach', 28.100230415341084), ('coast', 27.54021802790794)]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Model:\")\n",
    "print_topics(lda_model, tfidf_vectorizer)\n",
    "print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "### LDA Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -35021.54867560841\n",
      "Perplexity:  192.9520233059768\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 10,\n",
      " 'n_jobs': None,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': None,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import imp\n",
    "\n",
    "print_performance(lda_model, data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el224831405855632597288289864503\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el224831405855632597288289864503_data = {\"mdsDat\": {\"x\": [32.42095184326172, 0.648955225944519, 71.01968383789062, 3.7859814167022705, -42.666500091552734, -3.6216893196105957, -3.632401704788208, -36.58440017700195, 44.391380310058594, 40.235809326171875], \"y\": [8.115229606628418, 71.70709991455078, 9.971006393432617, 33.18513488769531, -9.22206974029541, -43.52651596069336, -4.171707630157471, 35.804412841796875, 50.61538314819336, -31.591665267944336], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [13.302028549826867, 10.026296017723796, 10.003756574080523, 9.64312546911536, 9.613072877921852, 9.567993989518934, 9.515401952874784, 9.470323065364193, 9.447783621891311, 9.410217881682383]}, \"tinfo\": {\"Term\": [\"say\", \"alic\", \"think\", \"littl\", \"look\", \"know\", \"begin\", \"come\", \"like\", \"queen\", \"king\", \"turtl\", \"thing\", \"time\", \"gryphon\", \"hatter\", \"mock\", \"head\", \"voic\", \"rabbit\", \"quit\", \"hear\", \"way\", \"make\", \"cat\", \"tone\", \"dormous\", \"duchess\", \"turn\", \"tell\", \"say\", \"alic\", \"make\", \"sit\", \"life\", \"lobster\", \"realli\", \"pool\", \"drink\", \"bottl\", \"small\", \"glass\", \"fanci\", \"glove\", \"fan\", \"foot\", \"break\", \"tear\", \"stop\", \"convers\", \"manag\", \"parti\", \"children\", \"help\", \"gener\", \"direct\", \"dodo\", \"sight\", \"lie\", \"serpent\", \"pigeon\", \"offend\", \"rabbit\", \"noth\", \"sort\", \"shout\", \"king\", \"let\", \"execut\", \"juri\", \"majesti\", \"wit\", \"place\", \"look\", \"alway\", \"till\", \"know\", \"march\", \"read\", \"littl\", \"begin\", \"queen\", \"speak\", \"right\", \"feel\", \"good\", \"shall\", \"arm\", \"live\", \"hastili\", \"read\", \"stand\", \"mouth\", \"puzzl\", \"answer\", \"draw\", \"rest\", \"appear\", \"surpris\", \"glad\", \"hardli\", \"sing\", \"butter\", \"manag\", \"drink\", \"bottl\", \"pool\", \"small\", \"glass\", \"chapter\", \"round\", \"lobster\", \"life\", \"sit\", \"look\", \"know\", \"mock\", \"long\", \"tri\", \"eye\", \"end\", \"pleas\", \"garden\", \"half\", \"till\", \"let\", \"curiou\", \"happen\", \"someth\", \"hous\", \"silenc\", \"watch\", \"lesson\", \"listen\", \"mani\", \"drink\", \"bottl\", \"pool\", \"small\", \"glass\", \"fanci\", \"glove\", \"fan\", \"foot\", \"gryphon\", \"open\", \"low\", \"lobster\", \"life\", \"realli\", \"sit\", \"say\", \"hatter\", \"voic\", \"rabbit\", \"round\", \"repli\", \"cours\", \"remark\", \"caterpillar\", \"tea\", \"wish\", \"howev\", \"tabl\", \"set\", \"sea\", \"mad\", \"hold\", \"high\", \"confus\", \"tail\", \"everi\", \"ear\", \"play\", \"direct\", \"help\", \"parti\", \"convers\", \"break\", \"foot\", \"glove\", \"small\", \"like\", \"king\", \"time\", \"quit\", \"white\", \"great\", \"wonder\", \"hurri\", \"anoth\", \"anyth\", \"tree\", \"execut\", \"cook\", \"wit\", \"babi\", \"join\", \"ought\", \"shake\", \"alway\", \"explain\", \"shout\", \"bottl\", \"drink\", \"pool\", \"small\", \"glass\", \"fanci\", \"glove\", \"fan\", \"foot\", \"sing\", \"far\", \"dear\", \"alic\", \"lobster\", \"life\", \"realli\", \"say\", \"come\", \"gryphon\", \"head\", \"way\", \"day\", \"ask\", \"juri\", \"add\", \"sort\", \"child\", \"walk\", \"feet\", \"twinkl\", \"far\", \"trial\", \"sister\", \"sigh\", \"sound\", \"room\", \"sneez\", \"box\", \"serpent\", \"pigeon\", \"tear\", \"fanci\", \"drink\", \"bottl\", \"pool\", \"small\", \"glass\", \"hedgehog\", \"chang\", \"grow\", \"right\", \"look\", \"dormous\", \"turn\", \"use\", \"word\", \"grow\", \"talk\", \"chang\", \"away\", \"wait\", \"chapter\", \"open\", \"danc\", \"old\", \"low\", \"majesti\", \"follow\", \"interrupt\", \"anxious\", \"size\", \"peopl\", \"soldier\", \"els\", \"learn\", \"heart\", \"croquet\", \"nearli\", \"matter\", \"believ\", \"deal\", \"bird\", \"turtl\", \"tone\", \"mous\", \"hare\", \"larg\", \"minut\", \"run\", \"door\", \"cri\", \"soup\", \"sure\", \"finish\", \"bite\", \"close\", \"game\", \"want\", \"suppos\", \"mind\", \"queer\", \"swim\", \"hedgehog\", \"suddenli\", \"jump\", \"dinah\", \"grin\", \"fall\", \"lie\", \"glass\", \"drink\", \"bottl\", \"gryphon\", \"king\", \"think\", \"thing\", \"duchess\", \"tell\", \"write\", \"poor\", \"court\", \"face\", \"pig\", \"beauti\", \"creatur\", \"inde\", \"near\", \"certainli\", \"everyth\", \"book\", \"footman\", \"forget\", \"place\", \"reason\", \"afraid\", \"dodo\", \"children\", \"drink\", \"bottl\", \"pool\", \"small\", \"glass\", \"fanci\", \"glove\", \"puzzl\", \"look\", \"rabbit\", \"lobster\", \"life\", \"say\", \"hear\", \"cat\", \"march\", \"hand\", \"noth\", \"leav\", \"mean\", \"moment\", \"dear\", \"rememb\", \"repeat\", \"soon\", \"felt\", \"question\", \"eat\", \"perhap\", \"air\", \"idea\", \"better\", \"saw\", \"notic\", \"best\", \"consid\", \"gener\", \"stop\", \"drink\", \"bottl\", \"pool\", \"small\", \"glass\", \"soup\", \"door\", \"rabbit\", \"lobster\", \"life\"], \"Freq\": [426.0, 303.0, 134.0, 114.0, 102.0, 102.0, 94.0, 92.0, 90.0, 83.0, 81.0, 78.0, 78.0, 73.0, 65.0, 65.0, 65.0, 59.0, 56.0, 53.0, 52.0, 50.0, 50.0, 58.0, 48.0, 46.0, 46.0, 45.0, 45.0, 44.0, 425.6090227365874, 302.7421066798155, 57.905291743354454, 27.815744176593984, 15.563406946935123, 13.59575705306792, 10.19907126094941, 7.793942236666417, 6.1481275871213095, 0.07705831603571688, 0.07705831594196744, 0.07705831575017122, 0.07705831594090021, 0.07705831601253982, 0.07705831573799855, 0.07705831607387871, 0.07705831622713126, 0.07705831617934455, 0.07705831603556339, 0.07705831632514948, 0.07705831589522064, 0.07705831605132539, 0.07705831609797312, 0.07705831657634486, 0.0770583161546282, 0.07705831595688735, 0.0770583163051507, 0.07705831606039684, 0.07705831621385598, 0.07705831654546451, 0.07705831655409724, 0.07705846327288346, 0.0770583511555844, 0.07705835109551787, 0.07705831673326596, 0.07705831671890337, 0.07705831667233662, 0.07705831666453553, 0.07705831661620188, 0.0770583165763967, 0.0770583165399236, 0.07705831650809514, 0.07705831650402394, 0.07705831648697432, 0.07705831648465648, 0.07705831647011284, 0.07705831646261152, 0.07705831645779228, 0.07705831643532227, 113.38259869120517, 93.87978846385262, 83.05862187565604, 35.353338063343074, 28.456894123192345, 23.976311569017437, 23.383396750391793, 21.564591008418724, 20.06053814544023, 16.355169755858714, 15.94181950750751, 15.770119310808145, 14.345255629622121, 14.152488350276837, 13.458524742341076, 13.032999926778896, 12.542372498349252, 12.02528762287875, 11.691269818670635, 11.191892075172728, 11.009852690211922, 10.791087103898583, 10.745204088659385, 10.67446844122243, 9.895655701591052, 0.09495580559283588, 0.09495580449840464, 0.09495580563048693, 0.09495580457049968, 0.094955804491016, 0.09495589084713103, 0.09495587503535587, 0.09495580658207485, 0.09495580656108896, 0.09495580608684041, 101.87403402507744, 101.17137397935687, 64.62781492168197, 39.534723439906905, 38.54222534933851, 35.0763762553022, 28.611830965934434, 26.86566581494213, 21.656064717168356, 20.961822002593603, 20.452771953608956, 19.48890386233573, 19.395147196609944, 16.773120223983796, 15.569308093688727, 15.126836704935224, 12.981637028503405, 12.92389144153702, 11.265733280014283, 11.265008066596064, 10.680531705455598, 0.09502352453715857, 0.09502352381598643, 0.09502352467058854, 0.09502352371232668, 0.09502352356301944, 0.09502352370139061, 0.09502352357165708, 0.09502364112226877, 0.09502352406752977, 0.09502696834519724, 0.09502359446719123, 0.09502359441374808, 0.09502352561549646, 0.09502352541295166, 0.09502352502540115, 0.0950235250025222, 0.09502352494398657, 64.60702127765, 55.967838621312524, 52.98067492796167, 40.166265887659584, 36.17738772323815, 28.727773219083755, 28.658814419050962, 25.52145381904404, 21.730498140531093, 19.107095269665624, 18.60000333223225, 16.108490971692202, 16.10414063633365, 15.894635038840457, 15.719777149203308, 15.413277662464594, 14.951379513787067, 13.09196102317758, 12.393600331264793, 11.201827068042256, 10.743956506486988, 10.616218643120884, 10.241401815799584, 10.048642666080347, 9.922603202525023, 9.868506323592154, 9.495073341511292, 9.399076636263324, 8.62236688848774, 8.087352420553941, 90.00304055169353, 80.58453048542654, 73.06999095828526, 52.02675616114996, 42.19489760626874, 38.33161071714316, 24.540971946954567, 22.254517130767276, 20.091961968822844, 18.230149412691286, 15.799248334638849, 14.986190088862983, 14.092989458410772, 13.992508027114349, 13.924330776614996, 13.616280059299351, 13.158313379682623, 12.898633301793454, 12.395220787796102, 12.239085692959502, 12.086104713413599, 7.531934495512492, 0.09909010416848495, 0.09909010408368481, 0.0990901028728919, 0.09909010298059023, 0.09909010277890463, 0.099090102897479, 0.0990901027637899, 0.09909010281659018, 0.09909125692234949, 0.09909021436220379, 0.09909015413168934, 0.09909014889393963, 0.0990901054299526, 0.09909010458951169, 0.09909010431631753, 0.0990901041950119, 91.28829080696165, 64.78062629800033, 58.9537018263538, 49.65928239757166, 41.52102608678267, 32.42293287047874, 27.493315960539196, 26.250723524846833, 20.553129798238565, 19.214882088319865, 18.388496462269767, 15.177238730065634, 13.880627802600568, 13.204641360271063, 12.861533801970204, 12.838628508116786, 12.517218349756911, 12.057626826830397, 11.343956642207678, 11.266689512429847, 11.254085911349394, 10.368548857024049, 10.368548071685984, 9.650230397965927, 8.447995254040201, 0.09715749544641429, 0.09715749436537732, 0.09715749597117368, 0.09715749452699743, 0.09715749453628983, 0.09716005156025617, 0.09715762644260054, 0.0971575936095107, 0.09715755183380266, 0.09715754534220021, 45.236719759798845, 44.29254907084765, 33.52192607155026, 32.00977869866719, 31.40582976761758, 29.582793976603366, 25.530906941523554, 24.90583190435795, 20.619956870800355, 19.784279504717826, 19.370347218543305, 18.608340593245384, 18.490111992932366, 16.228973240101183, 15.37585248819246, 14.700244600387906, 14.543536596932501, 14.318294272557436, 12.501547284634215, 12.50037612426125, 12.29311667511171, 12.259515446322482, 12.013030052036996, 11.916844464459366, 11.856085032745419, 11.835625897379138, 11.803730941271091, 11.529986616251161, 11.334906661336593, 11.252638367891292, 77.97620928104094, 45.602092619706326, 35.53009076255056, 34.41694350780714, 32.98556893528267, 32.7008583797006, 29.025679363786264, 28.138672349114696, 25.79951550020173, 22.249304820327943, 21.042057849177038, 19.840445880709133, 18.729072334753862, 17.1516864371954, 15.906364144209743, 15.419522316204784, 14.03983008441212, 12.248811560998188, 11.992770644151255, 11.909650573808745, 11.559338861287625, 11.494619239003134, 10.995149214050489, 10.987067319703758, 10.884004539825103, 10.593481994389343, 10.26624628358261, 8.317759503712113, 0.10538576908617905, 0.10538576773422031, 0.10539949499235289, 0.10538821314421194, 133.1846420620686, 77.81140508940662, 44.87603108092272, 43.25213365082981, 26.37967417522078, 25.87566890272611, 24.565827704722125, 21.25810778370777, 19.9351936717027, 19.179716950270556, 15.911489438218501, 15.10692174071536, 14.8844820411443, 14.549702196422741, 14.297947775797633, 13.313036774689452, 13.182179021643668, 12.987807931226179, 12.207387397433141, 12.188944067418847, 10.995177663690647, 10.249407381269938, 9.96413433314949, 0.10363752755839603, 0.10363761219387321, 0.10363752763911195, 0.10363752657675404, 0.1036375266062257, 0.10363752689949762, 0.10363752675047516, 0.10363766756016965, 0.10363758069300065, 0.10363757383420591, 0.10363752912285443, 0.10363752872246662, 0.10363752826562306, 49.78811791317662, 47.56198666579638, 38.62543984794275, 38.17280844484256, 35.55142139205169, 33.36689358614616, 32.227159283203584, 29.970289418343274, 29.36761633680317, 28.782346084748045, 23.394529672692563, 22.727387506504314, 21.905072914178703, 19.623754033456677, 18.025761606299078, 16.789878480517114, 16.54918756209872, 15.241070607744422, 14.88490287315899, 14.790852062659914, 13.32829069010678, 12.003397839978692, 11.075517493309958, 10.051579459797907, 9.87052473052543, 0.1045102373381173, 0.1045102365062808, 0.1045102375537868, 0.10451023643654465, 0.10451023641467318, 0.10451249433017958, 0.10451031414649828, 0.10451028415154331, 0.10451023870587996, 0.10451023865444281], \"Total\": [426.0, 303.0, 134.0, 114.0, 102.0, 102.0, 94.0, 92.0, 90.0, 83.0, 81.0, 78.0, 78.0, 73.0, 65.0, 65.0, 65.0, 59.0, 56.0, 53.0, 52.0, 50.0, 50.0, 58.0, 48.0, 46.0, 46.0, 45.0, 45.0, 44.0, 426.51307107520506, 303.6461551079676, 58.8093400811094, 28.719792515933545, 16.46745529112469, 14.499805400070947, 11.103119600284353, 8.69799057346255, 7.052175922970972, 8.41395112033593, 8.966179992477299, 9.193480377510916, 9.331944402551596, 9.501194460817526, 10.229440532318787, 10.277904209120809, 10.37390091553517, 10.534179545989893, 10.747121137155167, 10.747333942195764, 10.781806541033024, 10.801430774381332, 10.84160345158417, 10.92747024059614, 10.928175867775765, 11.12022939041137, 11.126876498827453, 11.12692461983337, 11.141967161159187, 11.25249801051769, 11.252498077889932, 11.689419116503686, 53.8595026307194, 36.428017834683594, 21.437078948259973, 12.968121258984693, 81.46654947802432, 20.374986982885005, 15.868206633288871, 28.377265114452094, 16.254950337761144, 14.874524575041265, 13.084856517583804, 102.76011725158311, 13.277237329499782, 21.338855075965096, 102.05745710051362, 39.502036257285695, 16.65627015560388, 114.26874953141741, 94.7659393054631, 83.94477271865837, 36.239488904109315, 29.343045020888198, 24.86246241180343, 24.269547589807438, 22.450741847999243, 20.946688987501087, 17.241320597701385, 16.82797034884164, 16.65627015560388, 15.231406472840915, 15.038639192342105, 14.344675724347624, 13.919150768053042, 13.428523340188757, 12.911438466324347, 12.577420661740653, 12.078042916509292, 11.896003533297517, 11.677237944321652, 11.63135608677285, 11.56061928504689, 10.781806541033024, 7.052175922970972, 8.41395112033593, 8.69799057346255, 8.966179992477299, 9.193480377510916, 20.663377620265276, 41.045093531005, 14.499805400070947, 16.46745529112469, 28.719792515933545, 102.76011725158311, 102.05745710051362, 65.51389804659114, 40.420806563174324, 39.428308469849405, 35.96245937735067, 29.4979140906487, 27.751748936838478, 22.542147838460664, 21.84790512355996, 21.338855075965096, 20.374986982885005, 20.28123032015133, 17.65920334420583, 16.455391215020537, 16.01291982473683, 13.86772015033309, 13.809974565195093, 12.151816401976557, 12.151091188859217, 11.566614827314067, 7.052175922970972, 8.41395112033593, 8.69799057346255, 8.966179992477299, 9.193480377510916, 9.331944402551596, 9.501194460817526, 10.229440532318787, 10.277904209120809, 65.66459262482064, 20.249445134293936, 17.108071157247224, 14.499805400070947, 16.46745529112469, 11.103119600284353, 28.719792515933545, 426.51307107520506, 65.48584885338636, 56.846666195811, 53.8595026307194, 41.045093531005, 37.056215297551496, 29.606600793041437, 29.53764199344371, 26.40028139219484, 22.60932571559271, 19.985922842928602, 19.47883090419627, 16.98731854475195, 16.98296821009641, 16.773462614290715, 16.598604725055246, 16.29210523493078, 15.830207086974411, 13.970788599016416, 13.272427905608343, 12.080654640827342, 11.622784080425099, 11.495046215959679, 11.12022939041137, 10.92747024059614, 10.801430774381332, 10.747333942195764, 10.37390091553517, 10.277904209120809, 9.501194460817526, 8.966179992477299, 90.88505709245604, 81.46654947802432, 73.95200749982483, 52.90877270317195, 43.07691414957669, 39.21362725906689, 25.42298848685675, 23.136533673111632, 20.973978509988147, 19.112165953163753, 16.681264876472014, 15.868206633288871, 14.975006001623715, 14.874524575041265, 14.806347321782713, 14.49829660386346, 14.040329921730514, 13.780649843872629, 13.277237329499782, 13.121102236638484, 12.968121258984693, 8.41395112033593, 7.052175922970972, 8.69799057346255, 8.966179992477299, 9.193480377510916, 9.331944402551596, 9.501194460817526, 10.229440532318787, 10.277904209120809, 11.63135608677285, 14.088590622159783, 30.244212794389703, 303.6461551079676, 14.499805400070947, 16.46745529112469, 11.103119600284353, 426.51307107520506, 92.17223995626216, 65.66459262482064, 59.837650975576686, 50.54323154561582, 42.40497523814771, 33.30688202150527, 28.377265114452094, 27.134672676064625, 21.437078948259973, 20.098831243418136, 19.272445611620352, 16.061187878692316, 14.764578695352888, 14.088590622159783, 13.745482955192392, 13.7225777101787, 13.401167500679792, 12.94157597732859, 12.227905790583954, 12.150638665431657, 12.138035063129058, 11.25249801051769, 11.252498077889932, 10.534179545989893, 9.331944402551596, 7.052175922970972, 8.41395112033593, 8.69799057346255, 8.966179992477299, 9.193480377510916, 12.435062301315357, 26.41000491817876, 32.28492771229971, 29.343045020888198, 102.76011725158311, 46.11581760757813, 45.171647203708666, 34.40102391595695, 32.88887654350119, 32.28492771229971, 30.46189182222305, 26.41000491817876, 25.78492975013452, 21.499054716545793, 20.663377620265276, 20.249445134293936, 19.487438446316034, 19.369209838115527, 17.108071157247224, 16.254950337761144, 15.579342447556453, 15.422634445181123, 15.197392118062776, 13.380645128194226, 13.379473969190023, 13.172214524534397, 13.138613292426223, 12.892127898584711, 12.795942314779227, 12.735182878530393, 12.71472374397242, 12.682828789018542, 12.409084463515107, 12.214004506656396, 12.13173621275022, 78.85193015951145, 46.47781349549041, 36.4058116359487, 35.29266438598316, 33.86128981065151, 33.57657925532365, 29.901400240546952, 29.01439337794949, 26.6752363761876, 23.1250279574916, 21.917778723979897, 20.716166758689443, 19.60479321075459, 18.027407315427546, 16.78208502152341, 16.295243192283525, 14.91555096059678, 13.124532436390762, 12.868491520327591, 12.78537145027182, 12.435062301315357, 12.37034011358286, 11.870870091510213, 11.862788329107243, 11.759725416268294, 11.469202869256758, 11.141967161159187, 9.193480377510916, 7.052175922970972, 8.41395112033593, 65.66459262482064, 81.46654947802432, 134.06211117912898, 78.68887420468704, 45.753500198707634, 44.129602768127484, 27.25714329550753, 26.75313801927297, 25.443296829312008, 22.13557690168363, 20.812662791564676, 20.057186071512813, 16.78895855712669, 15.984390857346256, 15.761951158454648, 15.42717131473609, 15.175416894154196, 14.190505893066128, 14.05964906107509, 13.865277048163641, 13.084856517583804, 13.066413186913103, 11.872646780801157, 11.126876498827453, 10.84160345158417, 7.052175922970972, 8.41395112033593, 8.69799057346255, 8.966179992477299, 9.193480377510916, 9.331944402551596, 9.501194460817526, 14.344675724347624, 102.76011725158311, 53.8595026307194, 14.499805400070947, 16.46745529112469, 426.51307107520506, 50.6647143208147, 48.438583207936404, 39.502036257285695, 39.04940485229713, 36.428017834683594, 34.24348999414619, 33.10375569208389, 30.8468858242064, 30.244212794389703, 29.658942494886528, 24.271126082246422, 23.603983913432142, 22.781669321802198, 20.500350439640133, 18.902358011755304, 17.66647488741414, 17.425783970574923, 16.117667015760585, 15.761499281715693, 15.6674484705442, 14.20488709843788, 12.879994247139617, 11.952113902669856, 10.928175867775765, 10.747121137155167, 7.052175922970972, 8.41395112033593, 8.69799057346255, 8.966179992477299, 9.193480377510916, 23.1250279574916, 29.01439337794949, 53.8595026307194, 14.499805400070947, 16.46745529112469], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -0.7323, -1.073, -2.7271, -3.4603, -4.0409, -4.1761, -4.4636, -4.7325, -4.9697, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -9.3491, -1.7724, -1.9611, -2.0836, -2.9378, -3.1548, -3.3261, -3.3511, -3.4321, -3.5044, -3.7086, -3.7342, -3.745, -3.8397, -3.8533, -3.9036, -3.9357, -3.9741, -4.0162, -4.0443, -4.088, -4.1044, -4.1244, -4.1287, -4.1353, -4.2111, -8.8575, -8.8575, -8.8575, -8.8575, -8.8575, -8.8575, -8.8575, -8.8575, -8.8575, -8.8575, -1.8772, -1.8841, -2.3323, -2.8237, -2.8492, -2.9434, -3.1471, -3.2101, -3.4256, -3.4582, -3.4828, -3.5311, -3.5359, -3.6811, -3.7556, -3.7844, -3.9374, -3.9418, -4.0791, -4.0792, -4.1325, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -8.8545, -2.2959, -2.4394, -2.4943, -2.7712, -2.8758, -3.1063, -3.1087, -3.2247, -3.3855, -3.5141, -3.541, -3.6849, -3.6851, -3.6982, -3.7093, -3.729, -3.7594, -3.8922, -3.947, -4.0481, -4.0899, -4.1018, -4.1378, -4.1568, -4.1694, -4.1749, -4.2134, -4.2236, -4.3098, -4.3739, -1.9612, -2.0718, -2.1697, -2.5093, -2.7188, -2.8148, -3.2607, -3.3585, -3.4608, -3.558, -3.7011, -3.7539, -3.8154, -3.8226, -3.8274, -3.8498, -3.884, -3.904, -3.9438, -3.9564, -3.969, -4.4419, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -8.7728, -1.9424, -2.2854, -2.3796, -2.5512, -2.7302, -2.9775, -3.1424, -3.1887, -3.4334, -3.5007, -3.5447, -3.7366, -3.8259, -3.8758, -3.9021, -3.9039, -3.9293, -3.9667, -4.0277, -4.0345, -4.0356, -4.1176, -4.1176, -4.1894, -4.3224, -8.7878, -8.7878, -8.7878, -8.7878, -8.7878, -8.7878, -8.7878, -8.7878, -8.7878, -8.7878, -2.639, -2.66, -2.9387, -2.9848, -3.0039, -3.0637, -3.211, -3.2358, -3.4246, -3.466, -3.4871, -3.5273, -3.5336, -3.6641, -3.7181, -3.763, -3.7737, -3.7893, -3.925, -3.9251, -3.9418, -3.9446, -3.9649, -3.9729, -3.978, -3.9798, -3.9824, -4.0059, -4.023, -4.0303, -2.0897, -2.6262, -2.8757, -2.9076, -2.95, -2.9587, -3.0779, -3.109, -3.1958, -3.3438, -3.3996, -3.4584, -3.516, -3.604, -3.6794, -3.7105, -3.8042, -3.9407, -3.9618, -3.9688, -3.9986, -4.0042, -4.0487, -4.0494, -4.0588, -4.0859, -4.1173, -4.3277, -8.6962, -8.6962, -8.6961, -8.6962, -1.552, -2.0894, -2.6398, -2.6767, -3.1711, -3.1904, -3.2424, -3.387, -3.4512, -3.4899, -3.6767, -3.7286, -3.7434, -3.7662, -3.7836, -3.855, -3.8649, -3.8797, -3.9417, -3.9432, -4.0463, -4.1165, -4.1447, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -8.7106, -2.532, -2.5777, -2.7858, -2.7976, -2.8688, -2.9322, -2.9669, -3.0395, -3.0599, -3.08, -3.2872, -3.3162, -3.353, -3.463, -3.5479, -3.619, -3.6334, -3.7158, -3.7394, -3.7457, -3.8499, -3.9546, -4.035, -4.132, -4.1502, -8.6982, -8.6982, -8.6982, -8.6982, -8.6982, -8.6982, -8.6982, -8.6982, -8.6982, -8.6982], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0151, 2.0143, 2.0018, 1.9853, 1.9608, 1.9529, 1.9323, 1.9075, 1.8801, -2.6758, -2.7394, -2.7644, -2.7794, -2.7974, -2.8712, -2.8759, -2.8852, -2.9006, -2.9206, -2.9206, -2.9238, -2.9256, -2.9293, -2.9372, -2.9373, -2.9547, -2.9553, -2.9553, -2.9567, -2.9665, -2.9665, -3.0046, -4.5323, -4.1413, -3.6111, -3.1084, -4.9461, -3.5602, -3.3103, -3.8915, -3.3343, -3.2456, -3.1174, -5.1783, -3.132, -3.6065, -5.1715, -4.2223, -3.3587, 2.2922, 2.2906, 2.2893, 2.2752, 2.2693, 2.2637, 2.2628, 2.2597, 2.2567, 2.2472, 2.2459, 2.2453, 2.24, 2.2392, 2.2362, 2.2342, 2.2317, 2.2289, 2.2269, 2.2238, 2.2225, 2.221, 2.2207, 2.2202, 2.2142, -2.0077, -2.1843, -2.2175, -2.2478, -2.2729, -3.0827, -3.7691, -2.7285, -2.8558, -3.412, 2.2935, 2.2935, 2.2886, 2.28, 2.2795, 2.2773, 2.2717, 2.2698, 2.2621, 2.2608, 2.2598, 2.2577, 2.2575, 2.2507, 2.2469, 2.2453, 2.2362, 2.2359, 2.2265, 2.2265, 2.2225, -2.0048, -2.1813, -2.2145, -2.2449, -2.2699, -2.2849, -2.3028, -2.3767, -2.3814, -4.2359, -3.0595, -2.891, -2.7256, -2.8528, -2.4586, -3.409, -6.1071, 2.3254, 2.3233, 2.3225, 2.3173, 2.3149, 2.3088, 2.3087, 2.3051, 2.2993, 2.294, 2.2928, 2.2858, 2.2858, 2.2851, 2.2845, 2.2835, 2.2818, 2.274, 2.2704, 2.2634, 2.2603, 2.2594, 2.2566, 2.2551, 2.2541, 2.2536, 2.2504, 2.2495, 2.2419, 2.2358, 2.3323, 2.3312, 2.33, 2.3252, 2.3214, 2.3193, 2.3067, 2.3032, 2.2991, 2.2948, 2.2877, 2.2849, 2.2813, 2.2809, 2.2806, 2.2793, 2.2772, 2.2759, 2.2733, 2.2725, 2.2716, 2.2313, -1.923, -2.1328, -2.1631, -2.1882, -2.2031, -2.2211, -2.2949, -2.2997, -2.4234, -2.615, -3.379, -5.6855, -2.6438, -2.7711, -2.3769, -6.0253, 2.3371, 2.3332, 2.3319, 2.3291, 2.3257, 2.3198, 2.3151, 2.3136, 2.3046, 2.3018, 2.2998, 2.2901, 2.285, 2.2819, 2.2803, 2.2802, 2.2785, 2.276, 2.2717, 2.2712, 2.2711, 2.2649, 2.2649, 2.2591, 2.2472, -1.938, -2.1146, -2.1478, -2.1781, -2.2032, -2.5052, -3.2584, -3.4593, -3.3637, -4.6171, 2.333, 2.3326, 2.3264, 2.3252, 2.3247, 2.323, 2.3184, 2.3176, 2.3105, 2.3088, 2.3079, 2.3061, 2.3058, 2.2995, 2.2967, 2.2942, 2.2936, 2.2927, 2.2843, 2.2843, 2.2832, 2.283, 2.2816, 2.2811, 2.2807, 2.2806, 2.2804, 2.2788, 2.2776, 2.277, 2.3458, 2.338, 2.3327, 2.3319, 2.3308, 2.3306, 2.3273, 2.3264, 2.3236, 2.3184, 2.3162, 2.3138, 2.3113, 2.3072, 2.3034, 2.3018, 2.2965, 2.288, 2.2865, 2.2861, 2.284, 2.2836, 2.2804, 2.2803, 2.2796, 2.2776, 2.2751, 2.2569, -1.8465, -2.023, -4.0776, -4.2933, 2.3528, 2.3482, 2.34, 2.3393, 2.3267, 2.326, 2.3243, 2.3189, 2.3163, 2.3147, 2.3057, 2.3029, 2.3021, 2.3008, 2.2998, 2.2956, 2.2949, 2.294, 2.29, 2.2899, 2.2826, 2.2772, 2.275, -1.8608, -2.0374, -2.0706, -2.1009, -2.126, -2.1409, -2.1589, -2.5708, -4.5399, -3.8938, -2.5816, -2.7089, -5.9631, 2.3459, 2.3451, 2.3409, 2.3407, 2.339, 2.3374, 2.3365, 2.3345, 2.334, 2.3334, 2.3266, 2.3255, 2.3241, 2.3197, 2.3159, 2.3125, 2.3118, 2.3075, 2.3062, 2.3058, 2.2997, 2.2929, 2.2872, 2.2798, 2.2783, -1.8484, -2.025, -2.0582, -2.0886, -2.1136, -3.036, -3.2629, -3.8815, -2.5692, -2.6965]}, \"token.table\": {\"Topic\": [6, 9, 10, 1, 5, 5, 2, 7, 5, 2, 2, 6, 7, 5, 9, 2, 7, 10, 10, 7, 8, 9, 5, 6, 4, 2, 10, 4, 9, 7, 7, 6, 9, 8, 6, 4, 10, 4, 5, 4, 9, 9, 8, 7, 3, 7, 6, 7, 10, 8, 4, 9, 8, 7, 2, 1, 9, 4, 10, 7, 3, 4, 9, 5, 5, 3, 9, 8, 7, 6, 6, 2, 6, 10, 8, 7, 4, 9, 9, 8, 3, 10, 2, 8, 4, 2, 5, 8, 7, 6, 3, 10, 3, 2, 8, 2, 4, 6, 10, 7, 8, 4, 4, 4, 3, 4, 5, 10, 9, 7, 5, 8, 6, 5, 3, 8, 7, 10, 3, 3, 8, 1, 5, 3, 2, 2, 1, 3, 3, 7, 4, 7, 1, 2, 3, 10, 7, 10, 8, 8, 3, 10, 8, 2, 9, 7, 10, 10, 7, 7, 7, 5, 4, 7, 10, 9, 6, 9, 4, 3, 1, 9, 2, 2, 8, 10, 5, 4, 2, 1, 9, 4, 10, 10, 4, 2, 2, 6, 4, 8, 10, 1, 4, 6, 4, 5, 2, 5, 6, 7, 3, 2, 6, 1, 7, 4, 6, 7, 3, 10, 6, 6, 8, 2, 2, 10, 8, 8, 8, 2, 8, 4, 4, 7, 4, 6, 9, 9, 9, 3, 5, 8, 5, 3, 6, 7, 8, 6, 7, 4, 7, 6, 8, 3, 6, 5, 4, 5, 5, 7, 9], \"Freq\": [0.9581836608235369, 0.9264993899917681, 0.9755658642793977, 0.9978720128771666, 0.903802478045491, 0.9535625294207142, 0.9339650253546604, 0.9212106847832384, 0.9418084817864587, 0.954090693372679, 0.9548048386995206, 0.9607624027772563, 0.9695585848888952, 0.9455404290971592, 0.9472914062948076, 0.9919175675239791, 0.967033469333061, 0.931677434767873, 0.9516861138585287, 0.9067127579347805, 0.9691507477659689, 0.9161054650174353, 0.9508018154116157, 0.9062422330129861, 0.8675617854150004, 0.9515061199383995, 0.9909455814169118, 0.9848379876620109, 0.9723104575672888, 0.984475394099736, 0.9678959736178523, 0.9453285999514038, 0.9223727878129323, 0.9430085925584925, 0.9872820715128718, 0.9305129705359108, 0.9203392880604013, 0.9304633180456401, 0.9348911111275684, 0.979511298940336, 0.9825770680471995, 0.9530072961677669, 0.9746867706563093, 0.9422715099152756, 0.9368267950254326, 0.9749870436969523, 0.9904498178368609, 0.9006055298248181, 0.9588611281487709, 0.9272693480511446, 0.8992620249922805, 0.8987248129386353, 0.9650382703254995, 0.9758040155099674, 0.9680885731563442, 0.8508012371694059, 0.9835313102727621, 0.9464169620535254, 0.9522621457495339, 0.9133383967482642, 0.9831203627104418, 0.9105466820336705, 0.9225446719287834, 0.9452864048626947, 0.9145573126083879, 0.9732371090850135, 0.9486990148606762, 0.9590901935726973, 0.8798135119477448, 0.8572704309953446, 0.9227324683245781, 0.9653106600014817, 0.9339284312774806, 0.9656886722934681, 0.9654295716465477, 0.9628134210730235, 0.8756649037469358, 0.924631898244972, 0.9375939589841632, 0.953397624876744, 0.9759495926321773, 0.9150658006417425, 0.9246802902512968, 0.8701818757964169, 0.9472493208212475, 0.9476896886886917, 0.9690508799135311, 0.9353959901804088, 0.9602003844100234, 0.9898789804633703, 0.9611905526518598, 0.973126226730818, 0.9626708333690419, 0.9420035844477267, 0.9633730009203683, 0.9507979672130434, 0.9925808573624187, 0.9860012724109344, 0.9868801328552717, 0.9377972879840261, 0.9650132592203148, 0.915124889825777, 0.9475555131772387, 0.9206913277137159, 0.9367435898122672, 0.9754178828004962, 0.9508770981353846, 0.9306557819647422, 0.9384154913295404, 0.9725964817046431, 0.9656306794185273, 0.9266380572951396, 0.9514658967699225, 0.9942731160087961, 0.9896386101461243, 0.9745641759227794, 0.9308005702702773, 0.9636868206377691, 0.9052144663912789, 0.9325159331861171, 0.8975075815031949, 0.9716133863514037, 0.9902617974750714, 0.9052684922721508, 0.988896793422347, 0.928003160160082, 0.9655301994557457, 0.9895893575869982, 0.992602993535691, 0.935231087884631, 0.9639364431546668, 0.9227958060969387, 0.9862378989461, 0.9274883538247832, 0.9510129077717682, 0.9872908765002437, 0.9461611600710268, 0.9666576897693868, 0.9143182858634461, 0.9828279333955012, 0.9921558926897363, 0.9725455000860468, 0.9888531083991001, 0.930935294140776, 0.9516588301286583, 0.9437877095590658, 0.9882503122561868, 0.915177988386097, 0.9410219524484044, 0.9293099796244068, 0.938297315012454, 0.9259041683827975, 0.9258032763324139, 0.9716376017424999, 0.9622745968473345, 0.9609534445590476, 0.8886915537136622, 0.9170906829489538, 0.9569339516641213, 0.9729116554582048, 0.9197526638403002, 0.9718486101058347, 0.9062595941388017, 0.9887453061332981, 0.932510230981177, 0.9755930787079308, 0.9828237803157837, 0.9840417644289725, 0.9605992128205796, 0.9006477782824115, 0.9183851626564827, 0.9817980733342544, 0.9777826706060023, 0.947628054918465, 0.9714969462188632, 0.9294084490506954, 0.9542295279875646, 0.8995816772214996, 0.9745379181505446, 0.9698542465136922, 0.9573990320249628, 0.9987970566203008, 0.9538877194246264, 0.8886915590345377, 0.9421203527006526, 0.943351739379712, 0.9799230755468594, 0.9253460667393165, 0.9700647349822736, 0.8987209261915314, 0.9374287813046005, 0.9457194774140887, 0.947343879157432, 0.9749374054309686, 0.9715525578514767, 0.8922417358018764, 0.9053022069773827, 0.9110085458788235, 0.9723257132528789, 0.9744117808397404, 0.9796110771754446, 0.9272441023428624, 0.9513502011950159, 0.965797285182773, 0.9191534626144583, 0.9304817422619156, 0.8892237318456425, 0.9386176908237959, 0.9581262893681937, 0.9107435762597158, 0.9385726528692193, 0.9418790822017656, 0.9041299817442843, 0.9848370605174929, 0.9730498059403654, 0.9492908257678936, 0.9744026073821055, 0.9912455958780764, 0.9920774693924533, 0.9372574080849769, 0.9871266848323612, 0.9897195358482866, 0.9591598789709946, 0.989137031577783, 0.9457652410160835, 0.9740623316562945, 0.9891958236432759, 0.9482153394872326, 0.9883426750047712, 0.9851061416179691, 0.9767871321262457, 0.9339759137338995, 0.9205140311807757, 0.9413485838535539, 0.9892521406130207, 0.9750002020609624, 0.9506691359374762, 0.94120655281254, 0.9833619683588565, 0.9729733381945869, 0.9538783913677876], \"Term\": [\"add\", \"afraid\", \"air\", \"alic\", \"alway\", \"anoth\", \"answer\", \"anxious\", \"anyth\", \"appear\", \"arm\", \"ask\", \"away\", \"babi\", \"beauti\", \"begin\", \"believ\", \"best\", \"better\", \"bird\", \"bite\", \"book\", \"bottl\", \"box\", \"break\", \"butter\", \"cat\", \"caterpillar\", \"certainli\", \"chang\", \"chapter\", \"child\", \"children\", \"close\", \"come\", \"confus\", \"consid\", \"convers\", \"cook\", \"cours\", \"court\", \"creatur\", \"cri\", \"croquet\", \"curiou\", \"danc\", \"day\", \"deal\", \"dear\", \"dinah\", \"direct\", \"dodo\", \"door\", \"dormous\", \"draw\", \"drink\", \"duchess\", \"ear\", \"eat\", \"els\", \"end\", \"everi\", \"everyth\", \"execut\", \"explain\", \"eye\", \"face\", \"fall\", \"fan\", \"fanci\", \"far\", \"feel\", \"feet\", \"felt\", \"finish\", \"follow\", \"foot\", \"footman\", \"forget\", \"game\", \"garden\", \"gener\", \"glad\", \"glass\", \"glove\", \"good\", \"great\", \"grin\", \"grow\", \"gryphon\", \"half\", \"hand\", \"happen\", \"hardli\", \"hare\", \"hastili\", \"hatter\", \"head\", \"hear\", \"heart\", \"hedgehog\", \"help\", \"high\", \"hold\", \"hous\", \"howev\", \"hurri\", \"idea\", \"inde\", \"interrupt\", \"join\", \"jump\", \"juri\", \"king\", \"know\", \"larg\", \"learn\", \"leav\", \"lesson\", \"let\", \"lie\", \"life\", \"like\", \"listen\", \"littl\", \"live\", \"lobster\", \"long\", \"look\", \"low\", \"mad\", \"majesti\", \"make\", \"manag\", \"mani\", \"march\", \"matter\", \"mean\", \"mind\", \"minut\", \"mock\", \"moment\", \"mous\", \"mouth\", \"near\", \"nearli\", \"noth\", \"notic\", \"offend\", \"old\", \"open\", \"ought\", \"parti\", \"peopl\", \"perhap\", \"pig\", \"pigeon\", \"place\", \"play\", \"pleas\", \"pool\", \"poor\", \"puzzl\", \"queen\", \"queer\", \"question\", \"quit\", \"rabbit\", \"read\", \"realli\", \"reason\", \"remark\", \"rememb\", \"repeat\", \"repli\", \"rest\", \"right\", \"room\", \"round\", \"run\", \"saw\", \"say\", \"sea\", \"serpent\", \"set\", \"shake\", \"shall\", \"shout\", \"sigh\", \"sight\", \"silenc\", \"sing\", \"sister\", \"sit\", \"size\", \"small\", \"sneez\", \"soldier\", \"someth\", \"soon\", \"sort\", \"sound\", \"soup\", \"speak\", \"stand\", \"stop\", \"suddenli\", \"suppos\", \"sure\", \"surpris\", \"swim\", \"tabl\", \"tail\", \"talk\", \"tea\", \"tear\", \"tell\", \"thing\", \"think\", \"till\", \"time\", \"tone\", \"tree\", \"tri\", \"trial\", \"turn\", \"turtl\", \"twinkl\", \"use\", \"voic\", \"wait\", \"walk\", \"want\", \"watch\", \"way\", \"white\", \"wish\", \"wit\", \"wonder\", \"word\", \"write\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 7, 2, 5, 4, 9, 3, 6, 8, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el224831405855632597288289864503\", ldavis_el224831405855632597288289864503_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el224831405855632597288289864503\", ldavis_el224831405855632597288289864503_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el224831405855632597288289864503\", ldavis_el224831405855632597288289864503_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=               x          y  topics  cluster       Freq\n",
       "topic                                                  \n",
       "0      32.420952   8.115230       1        1  13.302029\n",
       "6       0.648955  71.707100       2        1  10.026296\n",
       "1      71.019684   9.971006       3        1  10.003757\n",
       "4       3.785981  33.185135       4        1   9.643125\n",
       "3     -42.666500  -9.222070       5        1   9.613073\n",
       "8      -3.621689 -43.526516       6        1   9.567994\n",
       "2      -3.632402  -4.171708       7        1   9.515402\n",
       "5     -36.584400  35.804413       8        1   9.470323\n",
       "7      44.391380  50.615383       9        1   9.447784\n",
       "9      40.235809 -31.591665      10        1   9.410218, topic_info=        Term        Freq       Total Category  logprob  loglift\n",
       "181      say  426.000000  426.000000  Default  30.0000  30.0000\n",
       "3       alic  303.000000  303.000000  Default  29.0000  29.0000\n",
       "218    think  134.000000  134.000000  Default  28.0000  28.0000\n",
       "124    littl  114.000000  114.000000  Default  27.0000  27.0000\n",
       "128     look  102.000000  102.000000  Default  26.0000  26.0000\n",
       "..       ...         ...         ...      ...      ...      ...\n",
       "202     soup    0.104512   23.125028  Topic10  -8.6982  -3.0360\n",
       "52      door    0.104510   29.014393  Topic10  -8.6982  -3.2629\n",
       "167   rabbit    0.104510   53.859503  Topic10  -8.6982  -3.8815\n",
       "126  lobster    0.104510   14.499805  Topic10  -8.6982  -2.5692\n",
       "121     life    0.104510   16.467455  Topic10  -8.6982  -2.6965\n",
       "\n",
       "[388 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "0         6  0.958184     add\n",
       "1         9  0.926499  afraid\n",
       "2        10  0.975566     air\n",
       "3         1  0.997872    alic\n",
       "4         5  0.903802   alway\n",
       "...     ...       ...     ...\n",
       "236       4  0.950669    wish\n",
       "237       5  0.941207     wit\n",
       "238       5  0.983362  wonder\n",
       "239       7  0.972973    word\n",
       "240       9  0.953878   write\n",
       "\n",
       "[241 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 7, 2, 5, 4, 9, 3, 6, 8, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vectorized = tfidf_vectorizer.fit_transform(post_alice)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(lda_model, data_vectorized, tfidf_vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'learning_decay': [0.5, 0.9],\n",
       "                         'n_components': [5, 15, 30]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import imp\n",
    "    \n",
    "search_params = {'n_components': [5, 15, 30], 'learning_decay': [.5, .9]}\n",
    "model = GridSearchCV( LatentDirichletAllocation(), param_grid=search_params)\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -8128.217389611175\n",
      "Model Perplexity:  184.6006708672652\n"
     ]
    }
   ],
   "source": [
    "best_lda_model = model.best_estimator_\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el224831405855632624166934764324\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el224831405855632624166934764324_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [22.877488248512368, 21.36738457977409, 19.654396847551798, 18.80541796166766, 17.29531236249408]}, \"tinfo\": {\"Term\": [\"say\", \"alic\", \"think\", \"come\", \"look\", \"know\", \"littl\", \"like\", \"time\", \"queen\", \"begin\", \"thing\", \"make\", \"king\", \"quit\", \"turtl\", \"turn\", \"tell\", \"hear\", \"dormous\", \"hatter\", \"way\", \"mock\", \"tri\", \"gryphon\", \"speak\", \"head\", \"rabbit\", \"duchess\", \"tone\", \"alic\", \"littl\", \"head\", \"voic\", \"cat\", \"great\", \"white\", \"eye\", \"hand\", \"long\", \"ask\", \"day\", \"door\", \"dear\", \"minut\", \"grow\", \"caterpillar\", \"run\", \"pleas\", \"poor\", \"cours\", \"shall\", \"felt\", \"hurri\", \"write\", \"open\", \"walk\", \"pig\", \"court\", \"hold\", \"say\", \"make\", \"turtl\", \"hatter\", \"way\", \"mock\", \"gryphon\", \"rabbit\", \"mous\", \"round\", \"march\", \"hare\", \"sure\", \"end\", \"face\", \"feet\", \"high\", \"mad\", \"near\", \"want\", \"everyth\", \"puzzl\", \"dinah\", \"certainli\", \"footman\", \"realli\", \"watch\", \"draw\", \"peopl\", \"life\", \"think\", \"know\", \"like\", \"begin\", \"king\", \"quit\", \"tone\", \"word\", \"remark\", \"mean\", \"good\", \"chang\", \"chapter\", \"anoth\", \"eat\", \"question\", \"wait\", \"curiou\", \"finish\", \"live\", \"hastili\", \"low\", \"close\", \"tree\", \"idea\", \"lobster\", \"answer\", \"babi\", \"anxious\", \"silenc\", \"look\", \"thing\", \"hear\", \"tri\", \"duchess\", \"sit\", \"use\", \"repli\", \"noth\", \"talk\", \"moment\", \"wonder\", \"cri\", \"away\", \"garden\", \"add\", \"sort\", \"let\", \"wish\", \"arm\", \"howev\", \"rememb\", \"anyth\", \"tabl\", \"soup\", \"feel\", \"beauti\", \"danc\", \"saw\", \"mouth\", \"come\", \"time\", \"queen\", \"turn\", \"tell\", \"dormous\", \"speak\", \"larg\", \"right\", \"leav\", \"soon\", \"half\", \"juri\", \"till\", \"happen\", \"tea\", \"repeat\", \"hous\", \"old\", \"someth\", \"bite\", \"perhap\", \"notic\", \"better\", \"execut\", \"twinkl\", \"far\", \"confus\", \"rest\", \"best\"], \"Freq\": [485.0, 345.0, 136.0, 110.0, 109.0, 105.0, 112.0, 96.0, 87.0, 87.0, 95.0, 83.0, 70.0, 63.0, 54.0, 57.0, 48.0, 48.0, 50.0, 46.0, 52.0, 52.0, 52.0, 47.0, 51.0, 43.0, 52.0, 50.0, 44.0, 42.0, 344.8998981528367, 111.62580669214718, 52.01131627217167, 44.23551308443876, 43.37153494917201, 33.86777539424302, 33.003797244702106, 32.13981909331549, 31.2758409399277, 30.4118627843669, 28.683906465940797, 28.683906465938648, 27.819928302611014, 27.81992830261093, 27.819928302609323, 27.819928302608943, 25.2279937927432, 24.364015614968615, 24.36401561496857, 23.500037432554485, 22.63605924498036, 21.77208105159274, 20.04412464438597, 20.044124644385622, 18.316168203378478, 17.45218996701872, 17.452189967011247, 15.724233453652566, 15.724233453633447, 14.860255171845498, 484.74788311929836, 69.4057112792603, 56.653977813143584, 52.09978727329922, 52.099787273299015, 52.099787273298645, 50.278111054053085, 49.36727294361654, 40.25889180053907, 37.526377439186085, 32.06134867705861, 28.417996127454305, 22.042129028739364, 18.398776263548434, 18.398776263537734, 17.487938046700847, 14.75542330389433, 14.755423303876247, 13.844585015175857, 13.844585015168164, 12.933746698525278, 12.933746698488141, 12.933746698484235, 12.933746698481505, 12.933746698476478, 12.02290834731509, 12.02290834729832, 12.022908347295148, 12.022908347283126, 11.112069952963129, 135.58761303786952, 105.17357412822182, 95.36259382318013, 94.38149579222811, 62.98635872980701, 54.15647638660003, 41.402201812028686, 30.610123175229692, 27.666828954361467, 27.66682895435944, 26.685730873726925, 25.704632788914406, 23.742436604643697, 21.780240396371827, 21.78024039636452, 20.79914228107245, 20.799142281072417, 18.836946022240607, 17.85584787554531, 16.87474971458571, 15.89365153667353, 15.893651536670864, 15.893651536670252, 15.893651536665734, 14.912553338378723, 14.912553338367701, 13.93145511529489, 13.93145511529071, 13.93145511528678, 13.931455115283407, 108.92401676855549, 82.25708915718933, 49.43625500082325, 46.35930177554251, 43.282348542699545, 37.128442046725404, 36.10279095900997, 35.077139869511605, 35.077139869510994, 32.000186588565, 32.00018658856463, 28.923233284256813, 26.87193106438914, 25.846279948126092, 24.8206288269348, 24.820628826934616, 23.794977700166505, 22.769326567060144, 21.74367542669742, 21.743675426696917, 20.718024277987553, 20.718024277986032, 20.718024277983236, 18.66672194990952, 18.666721949903906, 17.641070766890493, 16.615419568043322, 15.589768350150903, 14.56411710910627, 14.56411710909978, 109.76915907230176, 87.18288981204672, 87.18288981204667, 47.656918404195544, 47.65691840419522, 45.398291447691406, 43.139664487035446, 37.49309706225508, 36.363783572335265, 34.105156586202234, 28.458589072330046, 26.199962039715572, 25.07064851548729, 23.941334984963696, 23.94133498496146, 22.812021447188908, 22.812021447187547, 21.68270790101863, 21.682707901018333, 20.55339434503139, 20.5533943450311, 19.424080777486978, 16.036139980466377, 16.03613998046054, 14.906826337755124, 14.906826337754461, 14.906826337752005, 13.777512663976157, 13.777512663974377, 13.777512663973894], \"Total\": [485.0, 345.0, 136.0, 110.0, 109.0, 105.0, 112.0, 96.0, 87.0, 87.0, 95.0, 83.0, 70.0, 63.0, 54.0, 57.0, 48.0, 48.0, 50.0, 46.0, 52.0, 52.0, 52.0, 47.0, 51.0, 43.0, 52.0, 50.0, 44.0, 42.0, 345.70947452665496, 112.43538337708513, 52.82089348706817, 45.0450904745177, 44.18111236262306, 34.67735314419752, 33.813375034948294, 32.9493969260411, 32.085418817504745, 31.221440709371233, 29.493484494457643, 29.493484494458198, 28.629506387763875, 28.629506387763946, 28.629506387764334, 28.62950638776419, 26.037572071366903, 25.173593967349987, 25.173593967350055, 24.309615864193457, 23.44563776199249, 22.581659660869573, 20.853703462409793, 20.8537034624101, 19.125747270214777, 18.261769177055303, 18.26176917705673, 16.533812998270566, 16.53381299827455, 15.669834913533505, 485.5480600931512, 70.20588882871597, 57.454155514589075, 52.8999650471719, 52.89996504717191, 52.89996504717199, 51.078288860595144, 50.16745076740268, 41.059069840042746, 38.32655556400804, 32.86152701658657, 29.218174656534895, 22.84230804258814, 19.198955707957612, 19.198955707959296, 18.28811762731294, 15.555603396258265, 15.55560339626142, 14.644765324088828, 14.644765324090141, 13.733927255212262, 13.733927255216885, 13.733927255217646, 13.733927255217603, 13.733927255218749, 12.823089190411896, 12.823089190413917, 12.823089190414743, 12.823089190415853, 11.912251130695864, 136.37370663033718, 105.95966780771228, 96.1486875426278, 95.16758951613006, 63.772452669930075, 54.94257043300161, 42.18829609266301, 31.39621780829847, 28.452923731876847, 28.452923731876957, 27.471825706571405, 26.490727681366128, 24.528531631306766, 22.566335581823576, 22.566335581823992, 21.585237557350027, 21.585237557350194, 19.62304150908025, 18.64194348535989, 17.660845461982184, 16.679747439011116, 16.679747439011336, 16.67974743901122, 16.67974743901157, 15.698649416528726, 15.698649416529591, 14.717551394642095, 14.717551394642348, 14.717551394642292, 14.717551394643017, 109.70118381112032, 83.03425631206856, 50.21342246152936, 47.1364692872999, 44.05951611282788, 37.90560976291271, 36.879958704431495, 35.854307645893016, 35.85430764589301, 32.777354469878524, 32.77735446987855, 29.700401293114997, 27.64909917472765, 26.623448115331065, 25.597797055776322, 25.59779705577638, 24.572145996042924, 23.546494936106228, 22.520843875936983, 22.52084387593679, 21.495192815499827, 21.495192815499983, 21.49519281549995, 19.44389069364285, 19.443890693642924, 18.418239632106047, 17.392588570061466, 16.366937507406227, 15.341286444008936, 15.341286444009494, 110.52556431057928, 87.93929512466255, 87.93929512466254, 48.413324017913276, 48.41332401791325, 46.1546970945941, 43.8960701706309, 38.2495028571336, 37.12018939366422, 34.861562465749266, 29.21499513843297, 26.95636820330834, 25.827054734517393, 24.697741264749954, 24.697741264749645, 23.568427793857854, 23.568427793857644, 22.4391143216635, 22.439114321663457, 21.309800847946477, 21.30980084794646, 20.180487372436836, 16.792546931267577, 16.79254693126668, 15.6632334440989, 15.663233444098859, 15.663233444098474, 14.53391995211144, 14.533919952111038, 14.533919952111118], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.4849, -2.613, -3.3766, -3.5386, -3.5583, -3.8056, -3.8315, -3.858, -3.8853, -3.9133, -3.9718, -3.9718, -4.0024, -4.0024, -4.0024, -4.0024, -4.1002, -4.135, -4.135, -4.1711, -4.2086, -4.2475, -4.3302, -4.3302, -4.4203, -4.4686, -4.4686, -4.5729, -4.5729, -4.6294, -1.0762, -3.0199, -3.2229, -3.3067, -3.3067, -3.3067, -3.3422, -3.3605, -3.5645, -3.6348, -3.7922, -3.9128, -4.1669, -4.3475, -4.3475, -4.3983, -4.5682, -4.5682, -4.6319, -4.6319, -4.7, -4.7, -4.7, -4.7, -4.7, -4.773, -4.773, -4.773, -4.773, -4.8518, -2.2666, -2.5206, -2.6186, -2.6289, -3.0333, -3.1844, -3.4529, -3.7549, -3.856, -3.856, -3.8921, -3.9296, -4.009, -4.0953, -4.0953, -4.1413, -4.1413, -4.2404, -4.2939, -4.3504, -4.4103, -4.4103, -4.4103, -4.4103, -4.4741, -4.4741, -4.5421, -4.5421, -4.5421, -4.5421, -2.4414, -2.7222, -3.2314, -3.2957, -3.3644, -3.5177, -3.5457, -3.5745, -3.5745, -3.6664, -3.6664, -3.7675, -3.841, -3.8799, -3.9204, -3.9204, -3.9626, -4.0067, -4.0528, -4.0528, -4.1011, -4.1011, -4.1011, -4.2054, -4.2054, -4.2619, -4.3218, -4.3855, -4.4535, -4.4535, -2.35, -2.5804, -2.5804, -3.1844, -3.1844, -3.2329, -3.2839, -3.4242, -3.4548, -3.5189, -3.6999, -3.7826, -3.8267, -3.8728, -3.8728, -3.9211, -3.9211, -3.9719, -3.9719, -4.0254, -4.0254, -4.0819, -4.2735, -4.2735, -4.3466, -4.3466, -4.3466, -4.4254, -4.4254, -4.4254], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4727, 1.4678, 1.4596, 1.4569, 1.4565, 1.4514, 1.4508, 1.4501, 1.4495, 1.4487, 1.4472, 1.4472, 1.4463, 1.4463, 1.4463, 1.4463, 1.4434, 1.4423, 1.4423, 1.4411, 1.4399, 1.4385, 1.4354, 1.4354, 1.4318, 1.4297, 1.4297, 1.4248, 1.4248, 1.422, 1.5417, 1.5318, 1.5293, 1.5281, 1.5281, 1.5281, 1.5275, 1.5272, 1.5236, 1.5222, 1.5187, 1.5155, 1.5076, 1.5007, 1.5007, 1.4986, 1.4905, 1.4905, 1.4871, 1.4871, 1.4833, 1.4833, 1.4833, 1.4833, 1.4833, 1.4789, 1.4789, 1.4789, 1.4789, 1.4738, 1.6211, 1.6194, 1.6187, 1.6186, 1.6145, 1.6125, 1.6081, 1.6015, 1.5989, 1.5989, 1.5978, 1.5967, 1.5943, 1.5914, 1.5914, 1.5898, 1.5898, 1.586, 1.5838, 1.5813, 1.5786, 1.5786, 1.5786, 1.5786, 1.5755, 1.5755, 1.572, 1.572, 1.572, 1.572, 1.6639, 1.6616, 1.6554, 1.6544, 1.6532, 1.6503, 1.6497, 1.6491, 1.6491, 1.647, 1.647, 1.6445, 1.6425, 1.6414, 1.6402, 1.6402, 1.6389, 1.6375, 1.6359, 1.6359, 1.6342, 1.6342, 1.6342, 1.6302, 1.6302, 1.6279, 1.6253, 1.6224, 1.619, 1.619, 1.7479, 1.7461, 1.7461, 1.739, 1.739, 1.7382, 1.7374, 1.7348, 1.7341, 1.7328, 1.7285, 1.7263, 1.725, 1.7236, 1.7236, 1.7221, 1.7221, 1.7204, 1.7204, 1.7186, 1.7186, 1.7165, 1.7086, 1.7086, 1.7052, 1.7052, 1.7052, 1.7013, 1.7013, 1.7013]}, \"token.table\": {\"Topic\": [4, 1, 3, 3, 3, 4, 4, 1, 4, 3, 4, 3, 5, 5, 5, 1, 1, 2, 3, 3, 3, 5, 5, 1, 1, 4, 3, 4, 1, 1, 2, 1, 5, 2, 4, 3, 2, 2, 5, 1, 2, 5, 4, 2, 1, 3, 2, 4, 3, 1, 1, 2, 5, 1, 5, 2, 3, 2, 1, 4, 2, 1, 5, 4, 1, 3, 5, 3, 3, 5, 5, 4, 2, 3, 1, 3, 3, 1, 4, 3, 2, 2, 2, 3, 1, 2, 4, 2, 4, 2, 4, 5, 5, 1, 2, 5, 1, 1, 1, 2, 5, 3, 3, 2, 2, 3, 4, 5, 4, 5, 5, 2, 1, 4, 2, 1, 3, 4, 5, 5, 4, 4, 5, 2, 4, 4, 5, 5, 4, 3, 5, 5, 3, 3, 4, 5, 2, 5, 4, 1, 3, 1, 2, 2, 2, 1, 4, 4, 3, 1], \"Freq\": [0.9766465428851628, 0.9979477723958061, 0.9749035203447147, 0.951245191852816, 0.9512451918528033, 0.9769626250971393, 0.9768728081946652, 0.9832680165495407, 0.9765827434286375, 0.9512451918527998, 0.9774278240136581, 0.9877312273845901, 0.9632638714214493, 0.9528036494695746, 0.9854620486527769, 0.9732665770628656, 0.9601509668980271, 0.9465610060706576, 0.9814754925848522, 0.9784523737804109, 0.9592471383936305, 0.9952448620022203, 0.963263871421428, 0.9809927216944847, 0.9677138601767024, 0.9765236772950292, 0.968249493393165, 0.977580564034036, 0.9832680165495222, 0.9780119720110511, 0.9465610060706547, 0.9780119720110535, 0.9749820242081202, 0.9358119421777085, 0.9759526157728409, 0.9749035203446967, 0.9375509935959346, 0.9465610060710258, 0.9576566711805746, 0.9711862123555056, 0.9375509935958524, 0.9576566711806007, 0.9772920952023566, 0.929565324678951, 0.9590622613413176, 0.9655645622000717, 0.9465610060705787, 0.976646542885165, 0.9828251055604745, 0.9804669883142203, 0.9780119720110427, 0.978889487399665, 0.9645216226423645, 0.9661709630882993, 0.9717487823169679, 0.9583076399927523, 0.9592471383936365, 0.982987416979021, 0.9844589246247956, 0.9758346991293211, 0.9642827486594374, 0.9572532246044921, 0.9804308532249171, 0.9769626250971449, 0.9590622613413035, 0.9554962087507264, 0.9679771951150106, 0.9878873614297369, 0.9909430840284077, 0.9673328340553695, 0.9752861775316085, 0.976790815890469, 0.9234190816926998, 0.9880530086058791, 0.9961277014049488, 0.9625813235609382, 0.9554962087506738, 0.960878143941493, 0.9936082384276947, 0.9592471383936239, 0.9642827486592419, 0.9828235373294963, 0.9737831106828443, 0.9840816453119182, 0.9780119720110378, 0.9829874169790194, 0.9762837946365404, 0.9742061901507109, 0.9777537271561239, 0.9559729835323295, 0.9761728031585386, 0.9528036494695238, 0.9804308532249189, 0.9309065203474025, 0.9358119421776274, 0.9415035251304592, 0.9677138601769354, 0.953379959616724, 0.9872636463725656, 0.9465610060707071, 0.9893188235892613, 0.97288713845307, 0.9828444423773182, 0.9767289198565128, 0.9358119421779163, 0.984081645311922, 0.9769626250971378, 0.9758818110894191, 0.9761728031585384, 0.9632638714214545, 0.9698226379778273, 0.9914796527054807, 0.9533799596167265, 0.9777537271561594, 0.9988712546950634, 0.9742419437009984, 0.9512451918527565, 0.9761088195500084, 0.9854620486527761, 0.9584119342592456, 0.9767156683777208, 0.9771706856083051, 0.9795865514350662, 0.9631250904673159, 0.9771706856083089, 0.9762837946365411, 0.9758818110894104, 0.991462597822031, 0.9875442214092759, 0.997259687079195, 0.9717487823169558, 0.9893188235892612, 0.9718335130185628, 0.9592471383936103, 0.9758898087938439, 0.9914625978220305, 0.9920953408761921, 0.9576566711805772, 0.9761399216446043, 0.9767990148646962, 0.9728871384530624, 0.9309065203473297, 0.9559729835322438, 0.9358119421777688, 0.9829874169790208, 0.9759451686172227, 0.9768728081946568, 0.9764177835106437, 0.9873800783674732, 0.9411396974816276], \"Term\": [\"add\", \"alic\", \"anoth\", \"answer\", \"anxious\", \"anyth\", \"arm\", \"ask\", \"away\", \"babi\", \"beauti\", \"begin\", \"best\", \"better\", \"bite\", \"cat\", \"caterpillar\", \"certainli\", \"chang\", \"chapter\", \"close\", \"come\", \"confus\", \"cours\", \"court\", \"cri\", \"curiou\", \"danc\", \"day\", \"dear\", \"dinah\", \"door\", \"dormous\", \"draw\", \"duchess\", \"eat\", \"end\", \"everyth\", \"execut\", \"eye\", \"face\", \"far\", \"feel\", \"feet\", \"felt\", \"finish\", \"footman\", \"garden\", \"good\", \"great\", \"grow\", \"gryphon\", \"half\", \"hand\", \"happen\", \"hare\", \"hastili\", \"hatter\", \"head\", \"hear\", \"high\", \"hold\", \"hous\", \"howev\", \"hurri\", \"idea\", \"juri\", \"king\", \"know\", \"larg\", \"leav\", \"let\", \"life\", \"like\", \"littl\", \"live\", \"lobster\", \"long\", \"look\", \"low\", \"mad\", \"make\", \"march\", \"mean\", \"minut\", \"mock\", \"moment\", \"mous\", \"mouth\", \"near\", \"noth\", \"notic\", \"old\", \"open\", \"peopl\", \"perhap\", \"pig\", \"pleas\", \"poor\", \"puzzl\", \"queen\", \"question\", \"quit\", \"rabbit\", \"realli\", \"remark\", \"rememb\", \"repeat\", \"repli\", \"rest\", \"right\", \"round\", \"run\", \"saw\", \"say\", \"shall\", \"silenc\", \"sit\", \"someth\", \"soon\", \"sort\", \"soup\", \"speak\", \"sure\", \"tabl\", \"talk\", \"tea\", \"tell\", \"thing\", \"think\", \"till\", \"time\", \"tone\", \"tree\", \"tri\", \"turn\", \"turtl\", \"twinkl\", \"use\", \"voic\", \"wait\", \"walk\", \"want\", \"watch\", \"way\", \"white\", \"wish\", \"wonder\", \"word\", \"write\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 4, 3, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el224831405855632624166934764324\", ldavis_el224831405855632624166934764324_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el224831405855632624166934764324\", ldavis_el224831405855632624166934764324_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el224831405855632624166934764324\", ldavis_el224831405855632624166934764324_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
       "topic                                                    \n",
       "4      150.222153  -72.269554       1        1  22.877488\n",
       "3       51.163364 -159.968018       2        1  21.367385\n",
       "2      -73.144554   21.523815       3        1  19.654397\n",
       "1      -66.410133 -110.606438       4        1  18.805418\n",
       "0       54.417324   12.443444       5        1  17.295312, topic_info=       Term        Freq       Total Category  logprob  loglift\n",
       "181     say  485.000000  485.000000  Default  30.0000  30.0000\n",
       "3      alic  345.000000  345.000000  Default  29.0000  29.0000\n",
       "218   think  136.000000  136.000000  Default  28.0000  28.0000\n",
       "34     come  110.000000  110.000000  Default  27.0000  27.0000\n",
       "128    look  109.000000  109.000000  Default  26.0000  26.0000\n",
       "..      ...         ...         ...      ...      ...      ...\n",
       "227  twinkl   14.906826   15.663233   Topic5  -4.3466   1.7052\n",
       "70      far   14.906826   15.663233   Topic5  -4.3466   1.7052\n",
       "35   confus   13.777513   14.533920   Topic5  -4.4254   1.7013\n",
       "175    rest   13.777513   14.533920   Topic5  -4.4254   1.7013\n",
       "17     best   13.777513   14.533920   Topic5  -4.4254   1.7013\n",
       "\n",
       "[180 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "0         4  0.976647      add\n",
       "3         1  0.997948     alic\n",
       "5         3  0.974904    anoth\n",
       "6         3  0.951245   answer\n",
       "7         3  0.951245  anxious\n",
       "...     ...       ...      ...\n",
       "235       1  0.975945    white\n",
       "236       4  0.976873     wish\n",
       "238       4  0.976418   wonder\n",
       "239       3  0.987380     word\n",
       "240       1  0.941140    write\n",
       "\n",
       "[150 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, tfidf_vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to improve the performance of our topic modeling by tuning the number of components and learning rate, increasing our log-likelihood from -35021 to -8224 and we were able to reduce our perplexity from 193 to 185.  However, to the reader, topics threads remain somewhat perplexing so to speak. As stated in reference below 'optimizing for perplexity may not yield human interpretable topics'.\n",
    "\n",
    "We downloaded three texts and did an analysis on 'Alice in Wonderland' based on it having less sparsity and content with respect to the others.  It would be interesting to look at how these factors effect the models as well comparison of various pre-processing and vectorization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5u1rl0RS1d-"
   },
   "source": [
    "References:\n",
    "\n",
    "LDA Performance and Hyperparameter Tuning<br>\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/\n",
    "\n",
    "\n",
    "Evaluate Topic Models: Latent Dirichlet Allocation (LDA)<br>\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_nlp_topic_modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
